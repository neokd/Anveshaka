[
    {
        "key": "0",
        "url": "https://news.google.com/stories/CAAqNggKIjBDQklTSGpvSmMzUnZjbmt0TXpZd1NoRUtEd2pRbFpfN0JoRjBXakJqdWZJV0hTZ0FQAQ?hl=en-IN&gl=IN&ceid=IN%3Aen",
        "title": "News about GPT-4",
        "description": "Imagine that as you are boarding an airplane, half the engineers who built the plane tell you there is a 10 percent chance the plane will crash, killing you and everyone else onboard. Would you still board?New article co-authored with @tristanharris @aza : bit.ly/gpt-nyt",
        "summary": "Imagine that as you are boarding an airplane, half the engineers who built the plane tell you there is a 10 percent chance the plane will crash, killing you and everyone else onboard.\nWould you still board?New article co-authored with @tristanharris @aza : bit.ly/gpt-nyt",
        "keywords": [
            "half",
            "tell",
            "gpt4",
            "onboard",
            "engineers",
            "plane",
            "killing",
            "coauthored",
            "imagine",
            "tristanharris",
            "crash"
        ]
    },
    {
        "key": "1",
        "url": "https://news.google.com/articles/CBMijwFodHRwczovL3d3dy5idXNpbmVzc3RvZGF5LmluL3RlY2hub2xvZ3kvbmV3cy9zdG9yeS9lbG9uLWlzLW9idmlvdXNseS1hdHRhY2tpbmctdXMtc2FtLWFsdG1hbi1yZXNwb25kcy10by1lbG9uLW11c2tzLWNyaXRpY2lzbS0zNzQ4NjQtMjAyMy0wMy0yNtIBkwFodHRwczovL3d3dy5idXNpbmVzc3RvZGF5LmluL2FtcC90ZWNobm9sb2d5L25ld3Mvc3RvcnkvZWxvbi1pcy1vYnZpb3VzbHktYXR0YWNraW5nLXVzLXNhbS1hbHRtYW4tcmVzcG9uZHMtdG8tZWxvbi1tdXNrcy1jcml0aWNpc20tMzc0ODY0LTIwMjMtMDMtMjY?hl=en-IN&gl=IN&ceid=IN%3Aen",
        "title": "\u2018Elon is obviously attacking us,\u2019 Sam Altman responds to Elon Musk's criticism",
        "description": "In a recent episode of the Lex Fridman Podcast, OpenAI CEO Sam Altman shared his thoughts on the future of artificial intelligence, including GPT-4 and ChatGPT. Altman also touched on his relationship with Elon Musk, with whom he shares concerns about the potential downsides of AGI.\n\nAltman acknowledged that Musk has been critical of OpenAI on Twitter and other platforms, but he also expressed empathy for Musk's concerns about AGI safety. \"Elon is obviously attacking us...I have empathy because I believe he is, understandably so, really stressed about AGI safety,\" Altman said.\n\nDespite their differences, Altman still sees Musk as a hero and believes that he can contribute positively to the development of AGI. \"Despite him being a jerk on Twitter, I'm glad that he exists in the world. I wish he would do more to look at the hard work we're doing,\" he said.\n\nAltman also discussed the potential for GPT-4, the successor to OpenAI's GPT-3 language model, which has been hailed as a major breakthrough in natural language processing. He believes that GPT-4 will be even more powerful and capable of performing more complex tasks.\n\nHe also spoke about ChatGPT, a language model designed specifically for chatbot applications.\n\nMore about Lex Fridman\n\nLex Fridman is a well-known personality in the field of artificial intelligence and machine learning. He is a research scientist at MIT, where he works on computer vision, deep learning, and autonomous vehicles. Besides his academic achievements, Lex is also famous for his podcast, The Lex Fridman Podcast, where he interviews some of the brightest minds in science, technology, and society.\n\nAlso Read\n\nNetflix is going all in on gaming, 40 new games announced for 2023\n\nParents can be jailed for sharing their child's photos on social media in this country",
        "summary": "In a recent episode of the Lex Fridman Podcast, OpenAI CEO Sam Altman shared his thoughts on the future of artificial intelligence, including GPT-4 and ChatGPT.\nAltman also touched on his relationship with Elon Musk, with whom he shares concerns about the potential downsides of AGI.\nAltman acknowledged that Musk has been critical of OpenAI on Twitter and other platforms, but he also expressed empathy for Musk's concerns about AGI safety.\n\"Elon is obviously attacking us...I have empathy because I believe he is, understandably so, really stressed about AGI safety,\" Altman said.\nBesides his academic achievements, Lex is also famous for his podcast, The Lex Fridman Podcast, where he interviews some of the brightest minds in science, technology, and society.",
        "keywords": [
            "gpt4",
            "sam",
            "podcast",
            "language",
            "lex",
            "obviously",
            "musks",
            "responds",
            "twitter",
            "fridman",
            "agi",
            "criticism",
            "elon",
            "altman",
            "musk",
            "attacking",
            "safety"
        ]
    },
    {
        "key": "2",
        "url": "https://news.google.com/articles/CBMie2h0dHBzOi8vaW5kaWFuZXhwcmVzcy5jb20vYXJ0aWNsZS90ZWNobm9sb2d5L2FydGlmaWNpYWwtaW50ZWxsaWdlbmNlL2dwdC00LWhhcy1zb21lLWNhcmVlci1hZHZpY2UtZm9yLXlvdW5nLXBlb3BsZS04NTE3MDM0L9IBgAFodHRwczovL2luZGlhbmV4cHJlc3MuY29tL2FydGljbGUvdGVjaG5vbG9neS9hcnRpZmljaWFsLWludGVsbGlnZW5jZS9ncHQtNC1oYXMtc29tZS1jYXJlZXItYWR2aWNlLWZvci15b3VuZy1wZW9wbGUtODUxNzAzNC9saXRlLw?hl=en-IN&gl=IN&ceid=IN%3Aen",
        "title": "GPT-4 has some career advice for young people: 20 tips the bot thinks can help you",
        "description": "A rewarding career is something that every youth yearns for. Technology has today equipped millions to explore and find their own paths, something that was not possible a hundred years ago. Thanks to OpenAI\u2019s sensational chatbot ChatGPT, a lot of things have changed for good.\n\nWhile earlier, the normal course of action after graduating was to seek expert counsel to help decide on one\u2019s next career move. However, now, AI seems to have come up with a viable alternative that not only offers guidance but also motivates users in the right direction.\n\nRecently, an AI enthusiast took to his Twitter account to share the responses from GPT-4. Rowan Cheung asked GPT-4, \u201cwhat career advice would you like to give young people today.\u201d And according to Cheung, the response is \u2018scary good\u2019.\n\nResponse from GPT-4\n\n1. Discover your passion: Explore interests and related career paths.\n\n2. Develop a growth mindset: Embrace learning and challenges.\n\n3. Build a strong foundation: Develop core skills like critical thinking.\n\n4. Cultivate a professional network: Connect with people in your field.\n\n5. Connect with people in your field. Pursue internships: Gain practical experience to build your resume.\n\n6. Seek mentorship: Find experienced professionals for guidance.\n\n7. Stay updated: Follow industry trends, news, and developments.\n\n8. Invest in continuous learning: Take courses, workshops, and certifications.\n\n9. Develop a personal brand: Showcase expertise through online presence.\n\nAdvertisement\n\n10. Build a diverse skill set: Acquire complementary skills for an edge.\n\n11. Set SMART goals: Establish focused and achievable career objectives.\n\n12. Be open to change: Adapt to the evolving job market.\n\n13. Practice time management: Prioritize tasks and personal development.\n\n14. Learn from failure: Embrace setbacks as valuable lessons.\n\n15. Emphasize soft skills: Develop interpersonal skills like teamwork.\n\n16. Seek feedback: Request constructive criticism for improvement.\n\n17. Maintain work-life balance: Prioritize self-care and set boundaries.\n\n18. Be proactive: Actively pursue career opportunities.\n\n19. Develop resilience: Cultivate the ability to bounce back from adversity.\n\nAdvertisement\n\n20. Stay true to values: Align career choices with personal ethics.\n\nThe prompt and its above responses show how GPT-4 understands the intent behind users\u2019 questions. The AI bot came up with some of the most practical and sensible tips that are usually imparted by experienced career counsellors. Amid the chatter about AI taking jobs, this goes on to suggest that there is one more job profile that has a threat looming \u2013 career counsellors.\n\nGPT-4 is a multimodal large language model created by OpenAI that was launched on March 14. A predecessor to GPT-3, the GPT-4 is faster in response and able to handle much more nuanced instructions. As of now, the premium ChatGPT Plus offers access to ChatGPT powered by GPT-4. The Plus subscription is priced at USD 20 per month.",
        "summary": "While earlier, the normal course of action after graduating was to seek expert counsel to help decide on one\u2019s next career move.\nRowan Cheung asked GPT-4, \u201cwhat career advice would you like to give young people today.\u201d And according to Cheung, the response is \u2018scary good\u2019.\nEmphasize soft skills: Develop interpersonal skills like teamwork.\nThe AI bot came up with some of the most practical and sensible tips that are usually imparted by experienced career counsellors.\nAs of now, the premium ChatGPT Plus offers access to ChatGPT powered by GPT-4.",
        "keywords": [
            "gpt4",
            "skills",
            "chatgpt",
            "build",
            "ai",
            "thinks",
            "develop",
            "personal",
            "help",
            "20",
            "bot",
            "set",
            "tips",
            "young",
            "advice",
            "seek",
            "career"
        ]
    },
    {
        "key": "3",
        "url": "https://news.google.com/articles/CBMiOWh0dHBzOi8vbWFzaGFibGUuY29tL2FydGljbGUvZ3B0NC1mcmVha3ktdXNlcy12ZXJzdXMtZ3B0M9IBAA?hl=en-IN&gl=IN&ceid=IN%3Aen",
        "title": "5 freaky things GPT-4 can do that GPT-3 could not",
        "description": "It's faster, better, more accurate, and it's here to freak you out all over again. No, this isn't the tagline for a bad horror movie sequel. It's the new version of OpenAI's artificial intelligence model, GPT-4.\n\nWhen OpenAI launched ChatGPT in November, 2022, it launched a new era of AI adoption. Suddenly, there was a free and widely accessible tool allowing anyone to interact with generative AI and experiment with its advanced capabilities \u2014 and limitations. Cue the freakout. If you haven't seen instances of ChatGPT being creepy or enabling nefarious behavior have you been living under a rock that doesn't have internet access? And that was back when ChatGPT was powered by GPT-3.\n\nGPT-4 is more accurate than its predecessor, better able to understand complex and nuanced requests, and is so intelligent, it scored in the 90th percentile on the bar exam. It is also multimodal which means it can accept images as well as text. GPT-4 is currently only available to ChatGPT Plus subscribers, but those who are shelling out 20 bucks for the premium subscription have already sussed out what GPT-4 can do that GPT-3 couldn't.\n\n1. File lawsuits\n\nGPT-4 is able to take in and process much more information than GPT-3. DoNotPay.com(Opens in a new tab) is already working on a way to use it to generate lawsuits against robocallers. In this instance, taking down scammers is definitely a good thing, but it proves GPT-4 has the power to generate a lawsuit for just about anything.\n\n2. Automate your dating life\n\nParsing through matches on dating apps is a tedious, but necessary job. The intense scrutiny is a key part of determining someone's potential that only you can know \u2014 until now. GPT-4 can automate this by analyzing dating profiles and telling you if they're worth pursuing based on compatibility, and even generate follow-up messages. Call us old fashioned, but at least some element of dating should be left up to humans.\n\n3. Build websites from almost nothing\n\nWith a simple prompt, BetaList founder Marc Kohlbrugge got GPT-4 to make an entire website from scratch. It didn't just make a website, it basically re-made Nomad List, the popular site for remote workers. In the OpenAI live demo of GPT-4, President and Co-Founder Greg Brockman uploaded an image of a handwritten note for a website. Within a minute or so, GPT-4 had built a functioning website based on the image of the piece of paper. Unlike GPT-3, GPT-4 can handle image input, and accurately \"see\" whatever the image is.\n\n4. Show you all the jobs it could replace\n\nLawyers, developers, even sommeliers aren't safe. Want a list of jobs GPT-4 has the power to replace? GPT-4 can do that for you. Too bad GPT-4 can't understand irony, or can it?\n\n5. Convince a TaskRabbit worker to solve a CAPTCHA for it\n\nTo understand the risks and safety challenges GPT-4 is capable of creating, OpenAI and the Alignment Research Center conducted research(Opens in a new tab) simulating situations where GPT-4 could go off the rails. In one of those situations, GPT-4 found a TaskRabbit worker and convinced it to solve a CAPTCHA for it by claiming it was a person that had impaired vision. This very research was conducted so that OpenAI could tweak the model and provide guardrails to ensure something like this doesn't happen.\n\nBut now we know what it's capable of.",
        "summary": "GPT-4 is currently only available to ChatGPT Plus subscribers, but those who are shelling out 20 bucks for the premium subscription have already sussed out what GPT-4 can do that GPT-3 couldn't.\nBuild websites from almost nothingWith a simple prompt, BetaList founder Marc Kohlbrugge got GPT-4 to make an entire website from scratch.\nIn the OpenAI live demo of GPT-4, President and Co-Founder Greg Brockman uploaded an image of a handwritten note for a website.\nWithin a minute or so, GPT-4 had built a functioning website based on the image of the piece of paper.\nUnlike GPT-3, GPT-4 can handle image input, and accurately \"see\" whatever the image is.",
        "keywords": [
            "gpt4",
            "chatgpt",
            "freaky",
            "openai",
            "dating",
            "image",
            "generate",
            "worker",
            "gpt3",
            "website",
            "understand",
            "things"
        ]
    },
    {
        "key": "4",
        "url": "https://news.google.com/articles/CBMiYWh0dHBzOi8vbnltYWcuY29tL2ludGVsbGlnZW5jZXIvMjAyMy8wMy9vbi13aXRoLWthcmEtc3dpc2hlci1zYW0tYWx0bWFuLW9uLXRoZS1haS1yZXZvbHV0aW9uLmh0bWzSAQA?hl=en-IN&gl=IN&ceid=IN%3Aen",
        "title": "Sam Altman on What Makes Him \u2018Super Nervous\u2019 About AI",
        "description": "Photo-Illustration: Intelligencer; Photo: Getty Images\n\nOpenAI entered the Silicon Valley stratosphere last year with the release of two AI products, the image-generator DALLE-2 and the chatbot ChatGPT. (The company recently unveiled GPT-4, which can ace most standardized tests, among other improvements on its predecessor.) Sam Altman, OpenAI\u2019s co-founder, has become a public face of the AI revolution, alternately evangelical and circumspect about the potent force he has helped unleash on the world.\n\nIn the latest episode of On With Kara Swisher, Swisher speaks with Altman about the many possibilities and pitfalls of his nascent field, focusing on some of the key questions around it. Among them: How do we best to regulate a technology even its founders don\u2019t fully understand? And who gets the enormous sums of money at stake? Altman has lofty ideas for how generative AI could transform society. But as Swisher observes, he sounds like the starry-eyed tech founders she encountered a quarter-century ago \u2014 only some of whom stayed true to their ideals.\n\nKara Swisher: You started Loopt. That\u2019s where I met you.\n\nSam Altman: Yeah.\n\nSwisher: Explain what it was. I don\u2019t even remember, Sam. I\u2019m sorry.\n\nAltman: That\u2019s no problem. Well, it didn\u2019t work out. There\u2019s no reason to remember. It was a location-based social app for mobile phones.\n\nSwisher: Right. What happened?\n\nAltman: The market wasn\u2019t there, I\u2019d say, is the No. 1 thing.\n\nSwisher: Yeah. Because?\n\nAltman: Well, I think you can\u2019t force a market. You can have an idea about what people are going to like. As a start-up, part of your job is to be ahead of it, and sometimes you\u2019re right about that and sometimes you\u2019re not. Sometimes you make Loopt; sometimes you make OpenAI.\n\nSwisher: Right, exactly.\n\nAltman: Keep trying.\n\nSwisher: You started in 2015 after being at Y Combinator, and late last year, you launched ChatGPT. Talk about that transition. You reinvigorated Y Combinator in a lot of ways.\n\nAltman: I was handed such an easy task with Y Combinator. I don\u2019t know if I reinvigorated it. It was a super-great thing by the time I took over.\n\nSwisher: What I mean is I think it got more prominence; you changed things around. I don\u2019t mean to say it was failing.\n\nAltman: I think I scaled it more, and we took on longer-term, more ambitious projects. OpenAI, actually, was something I helped start while at YC. We funded other companies, some of which I\u2019m very closely involved with, like Helion, the nuclear-fusion company. I definitely had a thing that I was passionate about and we did more of it, but I just tried to keep P.G. and Jessica\u2019s vision going there and scale it up.\n\nSwisher: This is Paul Graham.\n\nAltman: Paul Graham.\n\nSwisher: And Jessica. You had shifted, though, to OpenAI. Why was that? When you\u2019re in this position, which is a high-profile position in Silicon Valley \u2014 king of start-ups, essentially \u2014 why go off? Is it that you wanted to be an entrepreneur again?\n\nAltman: No, I didn\u2019t.\n\nSwisher: You had started it as a nonprofit.\n\nAltman: I am not a natural fit for a CEO; being an investor, I think, suits me very well. I got convinced that AGI was going to happen and be the most important thing I could ever work on. I think it is going to transform our society in many ways, and I won\u2019t pretend that as soon as we started OpenAI, I was sure it was going to work, but it became clear over the intervening years, and certainly by 2018\u20132019, that we had a real chance here.\n\nSwisher: What was it that made you think that?\n\nAltman: A number of things. It\u2019s hard to point to just a single one, but by the time we made GPT-2, which was still weak in a lot of ways, you could look at the scaling laws and see what was going to happen. I was like, \u201cHmm. This can go very, very far.\u201d I got super-excited about it. I\u2019ve never stopped being super-excited about it.\n\nSwisher: Was there something you saw that scaled or what was the \u2026\n\nAltman: It was looking at the data of how predictably better we could make the system with more compute, with more data.\n\nSwisher: There had already been a lot of stuff going on at Google with the Mine. They had bought that earlier, right around then.\n\nAltman: Yeah. There had been a bunch of stuff, but somehow it wasn\u2019t quite the trajectory that has turned out to be the one that really works.\n\nSwisher: But it\u2019s interesting; I remember us talking about it in 2015. You wrote that superhuman machine intelligence is probably the greatest threat to the continued existence of humanity.\n\nAltman: Yep. I still think so.\n\nSwisher: We\u2019re going to get into that. Why did you write that then? And yet you also called it the greatest technology ever.\n\nAltman: I still believe both of those things. I think at this point more of the world would agree on that. At the time, it was considered an extremely crazy position.\n\nSwisher: You wrote that it was probably the greatest threat to continued existing humanity and also one of the greatest technologies that could improve humanity. Roll those two things out.\n\nAltman: Well, I think we\u2019re finally seeing little previews of this with ChatGPT, and especially when we put GPT-4 out. People can see this vision where \u2014 just to pick one example out of the thousands, everyone in the world can have an amazing AI tutor on their phone with them all the time for anything they want to learn. I mean, that\u2019s wonderful. That\u2019ll make the world much better.\n\nThe creative enhancement that people are able to get from using these tools to do whatever their creative work is \u2014 that\u2019s fantastic. The economic empowerment, all of these things \u2014 and again, we\u2019re seeing this only in the most limited, primitive, larval way. But at some point it\u2019s like, Well, now we can use these things to cure disease.\n\nSwisher: What is the threat? Because when I try to explain it to regular people who don\u2019t quite understand \u2014\n\nAltman: I\u2019m not a regular person?\n\nSwisher: No. You\u2019re not.\n\nAltman: I\u2019m so offended.\n\nSwisher: I\u2019m not a regular person. But when the internet started, nobody knew what it was going to do. But when you said superhuman machine intelligence is probably the greatest threat, what did you mean by that?\n\nAltman: I think there\u2019s levels of threats. Today, we can look at these systems and say, \u201cAll right. No imagination required, we can see how this can contribute to computer-security exploits, or disinformation, or other things that can destabilize society.\u201d\n\nCertainly, there\u2019s going to be an economic transition. Those are not in the future; those are things we can look at now. In the medium term, I think we can imagine that these systems get much, much more powerful. Now, what happens if a really bad actor gets to use them and tries to figure out how much havoc they can wreak on the world or harm they can inflict? And then, we can go further to all of the traditional sci-fi \u2014 what happens with the runaway AGI scenarios or anything like that?\n\nNow, the reason we\u2019re doing this work is because we want to minimize those downsides while still letting society get the big upsides, and we think it\u2019s very possible to do that. But it requires, in our belief, this continual deployment in the world, where you let people gradually get used to this technology, where you give institutions, regulators, policy-makers time to react to it, where you let people feel it, find the exploits, the creative energy the world will come up with \u2014 use cases we and all the red teamers we could hire would never imagine.\n\nAnd so we want to see all of the good and the bad, and figure out how to continually minimize the bad and improve the benefits. You can\u2019t do that in the lab. This idea that we have, that we have an obligation and society will be better off for us to build in public, even if it means making some mistakes along the way \u2014 I think that\u2019s really important.\n\nSwisher: When people critiqued ChatGPT, you wish that you said, \u201cWait for GPT-4.\u201d Now that it\u2019s out, has it met expectations?\n\nAltman: A lot of people seem really happy with it. There\u2019s plenty of things it\u2019s still bad at.\n\nSwisher: I meant your expectations.\n\nAltman: Yeah. I\u2019m proud of it. Again, a very long way to go, but as a step forward, I\u2019m proud of it.\n\nSwisher: What are you proudest of?\n\nAltman: Well, I enjoy using it, but more than that, it\u2019s very gratifying to just go search for GPT-4 on Twitter and read what people are doing with it, the amazing discoveries people make of how to use it to be more productive, more effective, more creative, whatever they need. It\u2019s nice. It\u2019s nice to build something that\u2019s useful for people.\n\nSwisher: You tweeted that at first glance, GPT-4 seems \u201cmore impressive than it actually is.\u201d Why is that?\n\nAltman: Well, I think that\u2019s been an issue with every version of these systems, not particularly GPT-4. You find these flashes of brilliance before you find the problems. And so, a thing that someone used to say about GPT-4 that has really stuck with me is it is the world\u2019s greatest demo creator. Because you can tolerate a lot of mistakes there, but if you need a lot of reliability for a production system, it\u2019s not as good at that. GPT-4 makes fewer mistakes. It\u2019s more reliable, it\u2019s more robust, but there\u2019s still a long way to go.\n\nSwisher: One of the issues is hallucinations, which is a creepy word, I have to say.\n\nAltman: What do you think we should call it instead?\n\nSwisher: Mistakes, or something like that. Hallucination feels like it\u2019s sentient.\n\nAltman: It\u2019s interesting. Hallucination \u2014 that word doesn\u2019t trigger for me as sentient, but I really try to make sure we\u2019re picking words that are in the tools camp, not the creature\u2019s camp. Because I think it\u2019s tempting to anthropomorphize this in a really bad way.\n\nSwisher: That\u2019s correct. But anyway, sometimes a bot just makes things up out of thin air. Hallucinations happen. It\u2019ll cite research papers or news articles that don\u2019t exist. You said GPT-4 does this less than GPT-3 \u2014 we should give them actual names \u2014but it still happens.\n\nAltman: No. That would be anthropomorphizing.\n\nSwisher: That\u2019s true.\n\nAltman: I think it\u2019s good that it\u2019s letters plus a number.\n\nSwisher: Not like Barbara?\n\nAltman: I don\u2019t think so.\n\nSwisher: Anyway, but it still happens. Why is that?\n\nAltman: These systems are trained to do something, which is to predict the next word in a sequence. And so, it\u2019s trying to just complete a pattern, and given its training set, this is the most likely completion. That said, the decrease from 3 to 3.5 to 4, I think is very promising. We track this internally, and every week we\u2019re able to get the number lower and lower and lower. I think it\u2019ll require combinations of model scale, new ideas \u2014\n\nSwisher: More data.\n\nAltman: A lot of user feedback.\n\nSwisher: Model scale is more data.\n\nAltman: Not necessarily more data, but more compute thrown at the problem. Human feedback \u2014 people flagging the errors for us, developing new techniques of the model \u2014 can tell when it\u2019s about to go off the rails.\n\nSwisher: Real people just saying \u201cThis is a mistake.\u201d\n\nAltman: Yeah.\n\nSwisher: One of the issues is that it obviously compounds a very serious misinformation problem.\n\nAltman: Yeah. We pay experts to flag, to go through and label the data for us.\n\nSwisher: These are bounties.\n\nAltman: Not just bounties, but we employ people. We have contractors; we work with external firms. We say we need experts in this area to help us go through and improve things. You don\u2019t just want to rely totally on random users doing whatever, trying to troll you, or anything like that.\n\nSwisher: So humans, more compute. What else?\n\nAltman: I think that there is going to be a big new algorithmic idea, a different way that we train or use or tweak these models, different architecture perhaps. So I think we\u2019ll find that at some point.\n\nSwisher: Meaning what, for the non-techy?\n\nAltman: Well, it could be a lot of things. You could say a different algorithm, but just some different idea of the way that we create or use these models that encourages, during training or inference time when you\u2019re using it, that encourages the models to really ground themselves in truth, be able to cite sources. Microsoft has done some good work there. We\u2019re working on some things.\n\nSwisher: Talk about the next steps. How does this move forward?\n\nAltman: I think we\u2019re on this very long-term exponential, and I don\u2019t mean that just for AI, although AI too \u2014 I mean that as cumulative, human, technological progress \u2014 and it\u2019s very hard to calibrate that, and we keep adjusting our expectations.\n\nI think if we told you five years ago we\u2019d have GPT-4 today, you\u2019d maybe be impressed. But if we told you four months ago after you used ChatGPT that we\u2019d have GPT-4 today, probably not that impressed. Yet it\u2019s the same continued exponential, so maybe where we get to a year from now, you\u2019re like, \u201cMeh. It\u2019s better, but the new iPhone\u2019s always a little better too.\u201d But if you look at where we\u2019ll be in ten years, then I think you\u2019d be pretty impressed.\n\nSwisher: Right. Actually, the old iPhones were not as impressive as the new ones.\n\nAltman: For sure, but it\u2019s been such a gradual process that unless you hold that original one and this one back-to-back \u2014\n\nSwisher: I just found mine the other day, interestingly enough. That\u2019s a very good comparison.\n\nYou\u2019re getting criticism for being secretive, and you said competition and safety require it. Critics say that\u2019s a cop-out and it\u2019s just about competition. What\u2019s your response?\n\nAltman: It\u2019s clearly not. We make no secret that we would like to be a successful effort, and I think that\u2019s fine and good, and we try to be clear, but also we have made many decisions over the years in the name of safety that have been widely ridiculed at the time that people come to appreciate later. Even in the early versions of GPT, when we talked about not releasing model weights or releasing them gradually because we wanted people to have time to adapt \u2014 we got ridiculed for that, and I totally stand by that decision. Would you like us to push a button and open source GPT-4 and drop those weights into the world?\n\nSwisher: Probably not.\n\nAltman: Probably not.\n\nSwisher: One of the excuses that tech always uses is you don\u2019t understand it, we need to keep it in the back room. It\u2019s often about competition.\n\nAltman: Well, for us it\u2019s the opposite. I mean, what we\u2019ve said all along \u2014 and this is different than what most other AGI efforts have thought \u2014 is everybody needs to know about this. AGI should not be built in a secret lab with only the people who are privileged and smart enough to understand it. Part of the reason that we deploy this is, I think, we need the input of the world, and the world needs familiarity with what is in the process of happening, the ability to weigh in, to shape this together. We want that. We need that input, and people deserve it. So I think we\u2019re not the secretive company. We\u2019re quite the opposite. We put the most advanced AI in the world in an API that anybody can use. I don\u2019t think that if we hadn\u2019t started doing that a few years ago, Google or anybody else would be doing it now. They would just be using it secretly to make Google search better.\n\nSwisher: But you are in competition. And let me go back to someone who was one of your original funders, Elon Musk. He\u2019s been openly critical of OpenAI, especially as it\u2019s gone to profits: \u201cOpenAI was created as an open source (which is why I named it \u201cOpen\u201d AI), nonprofit company to serve as a counterweight to Google, but now it has become a closed source, maximum-profit company effectively controlled by Microsoft. Not what I intended at all.\u201d We\u2019re talking about open source versus closed, but what about his critique that you\u2019re too close to the big guys?\n\nAltman: I mean, most of that is not true. And Elon knows that. We\u2019re not controlled by Microsoft. Microsoft doesn\u2019t even have a board seat on us, we are an independent company. We have an unusual structure where we can make very different decisions than what most companies do. I think a fair part of that is we don\u2019t open-source everything anymore. We\u2019ve been clear about why we think we were wrong there originally. We still do open-source a lot of stuff. Open sourcing CLIP was something that kicked off this whole generative image world. We recently open-sourced Whisper, we open-sourced tools, we\u2019ll open-source more stuff in the future. But I don\u2019t think it would be good right now for us to open-source GPT-4, for example. I think that would cause some degree of havoc in the world, or at least there\u2019s a chance of that \u2014 we can\u2019t be certain that it wouldn\u2019t. And by putting it out behind an API, we are able to get many, not all, but many of the benefits we want of broad access to this society being able to understand the update and think about it. But when we find some of the scarier downsides, we\u2019re able to then fix them, and we are going to.\n\nSwisher: How do you respond when he\u2019s saying you\u2019re a closed-source maximum-profit company? I\u2019ll leave out the control by Microsoft, but in a strong partnership with Microsoft. Which was against what he said. I remember years ago, this was something he talked about a lot and was \u2014\n\nAltman: Was what part?\n\nSwisher: \u201cOh, we don\u2019t want these big companies to run it. If they run it, we\u2019re doomed.\u201d He was much more dramatic than most people.\n\nAltman: So we\u2019re a capped-profit company. We invented this new thing where we started as a nonprofit \u2014\n\nSwisher: Explain that. Explain what a capped profit is.\n\nAltman: Our shareholders, who are our employees and our investors, can make a certain return. Their shares have a certain price that they can get to. But if OpenAI goes and becomes a multitrillion-dollar company, almost all of that flows to the nonprofit that controls us.\n\nSwisher: What is the cap?\n\nAltman: It continues to vary as we have to raise more money, but it\u2019s much, much, much, and will remain much, smaller than any \u2014\n\nSwisher: Smaller than what?\n\nAltman: \u2026 tech company.\n\nSwisher: What?\n\nAltman: In terms of a number, I truly don\u2019t know off the top of my head.\n\nSwisher: But it\u2019s not significant. The nonprofit gets a significant chunk of the revenue.\n\nAltman: Well, no, it gets everything over a certain amount. So if we\u2019re not very successful, the nonprofit gets a little bit along the way, but it won\u2019t get any appreciable amount. The goal of the cap profit is in the world where we do succeed at making AGI and we have a significant lead over everybody else, it could become much more valuable, I think, than maybe any company out there today. That\u2019s when you want almost all of it to flow to a nonprofit, I think.\n\nSwisher: I want to get back to what Elon was talking about. He was very adamant at the time and, again, overly dramatic, that Google and Microsoft and Amazon were going to kill us. I think he had those kinds of words, that there needed to be an alternative. What changed, in your estimation?\n\nAltman: Of?\n\nSwisher: To change from that idea.\n\nAltman: Oh, it was very simple. When we realized the level of capital we were going to need to do this, scaling turned out to be far more important than we thought, and we even thought it was going to be important then. And we tried for a while to find a path to that level of capital as a nonprofit. There was no one that was willing to do it. So we didn\u2019t want to become a fully for-profit company. We wanted to find something that would let us get the access to and the power of capitalism to finance what we needed to do, but still be able to fulfill and be governed by the nonprofit mission. So having this nonprofit that governs the capped-profit LLC, given the playing field that we saw at the time, and I still think that we see now, was the way to get to the best of all worlds. In a really well-functioning society, I think this would\u2019ve been a government project.\n\nSwisher: That\u2019s correct. I was just going to make that point. The government would\u2019ve been your funder.\n\nAltman: We talked to them. They not just would have been our funder, but they would\u2019ve started the project. We\u2019ve done things like this before in this country.\n\nBut the answer is not to just say, \u201cOh well, the government doesn\u2019t do stuff like this anymore, so we\u2019re just going to sit around and let other countries run by us and get an AGI and do whatever they want to us.\u201d We\u2019re going to look at what\u2019s possible on this playing field.\n\nSwisher: Right. So Elon used to be the co-chair, and you have a lot of respect for him.\n\nAltman: I do.\n\nSwisher: I\u2019m sure you thought deeply about his critiques. Have you spoken to him directly? Was there a break, or what? You two were very close, as I recall.\n\nAltman: We\u2019ve spoken directly recently.\n\nSwisher: And what do you make of the critiques? When you hear them from him, I mean, he can be quite in your face about things.\n\nAltman: He\u2019s got his style.\n\nSwisher: Yeah.\n\nAltman: To say a positive thing about Elon \u2014\n\nSwisher: Yeah, I\u2019d like you to.\n\nAltman: \u2026 I think he really does care about a good future with AGI.\n\nSwisher: He does.\n\nAltman: And \u2026 I mean, he\u2019s a jerk, whatever else you want to say about him. He has a style that is not a style that I\u2019d want to have for myself.\n\nSwisher: He\u2019s changed.\n\nAltman: But I think he does really care, and he is feeling very stressed about what the future\u2019s going to look like \u2014\n\nSwisher: For humanity.\n\nAltman: For humanity.\n\nSwisher: When we did an interview at Tesla, he was like, \u201cIf this doesn\u2019t work, we\u2019re all doomed.\u201d Which was sort of centered on his car, but nonetheless, he was correct. And this was something he talked about almost incessantly, the idea of either AI taking over and killing us, or maybe it doesn\u2019t really care. Then he decided it was like anthills; do you remember that example?\n\nAltman: I don\u2019t remember the anthills part.\n\nSwisher: He said, \u201cYou know how, when we\u2019re building a highway, anthills are there and we just go over them without thinking about it?\u201d And then he said, \u201cWe\u2019re like a cat, and maybe they\u2019ll feed us and bell us, but they don\u2019t really care about us.\u201d It went on and on; it changed and iterated over time. But I think the critique that I would most agree with him on is that big companies would control this and there couldn\u2019t be innovation in the space.\n\nAltman: Well, I would say we\u2019re evidence against that.\n\nSwisher: Except Microsoft, and that\u2019s why I think \u2014\n\nAltman: They\u2019re a big investor, but again, not even a board member. Like true, full independence from them.\n\nSwisher: So you think you are a startup in comparison with a giant partner?\n\nAltman: Yeah, I mean, we\u2019re a big start-up at this point.\n\nSwisher: And there\u2019s no way to be a nonprofit that would work?\n\nAltman: If someone wants to give us tens of billions of dollars of nonprofit capital, we can go make that work.\n\nSwisher: Yeah. Or the government, which they\u2019re not.\n\nAltman: We tried.\n\nSwisher: Greg Brockman, your co-founder, said you guys made a mistake by creating AI with a quote, \u201cLeft-leaning political bias.\u201d What do you think of the substance of those critiques?\n\nAltman: Yeah. I think the reinforcement learning from human feedback on our first version of ChatGPT was pretty left-biased, but that is now no longer true. It\u2019s just become an internet meme. There are some people who are intellectually honest about this. If you go look at GPT-4 and test it on \u2026 It\u2019s relatively neutral. Not to say we don\u2019t have more work to do. The main thing, though, is I don\u2019t think you ever get two people agreeing that any one system is unbiased on every topic. And so giving users more control and also teaching people about how these systems work, that there is some randomness in a response, that the worst screenshot you see on Twitter is not representative of what these things do, I think is important.\n\nSwisher: So when you said it had a left-leaning bias, what did that mean to you? And of course they\u2019ll run with that \u2014 they\u2019ll run with that quite far.\n\nAltman: People would give it these tests that score you on the political spectrum in America or whatever. And one would be all the way on the right, ten would be all the way on the left. It would get like a ten on all of those tests, the first version.\n\nSwisher: Why?\n\nAltman: A number of reasons, but largely because of the reinforcement learning from human feedback stuff.\n\nSwisher: What do you think the most viable threat to OpenAI is? I hear you\u2019re watching Claude very carefully. This is the bot from Anthropic, a company that\u2019s founded by former OpenAI folks and backed by Alphabet. Is that it? We\u2019re recording this on Tuesday. BARD launched today; I\u2019m sure you\u2019ve been discussing it internally. Talk about those two to start.\n\nAltman: I try to pay some attention to what\u2019s happening with all these other things. It\u2019s going to be an unbelievably competitive space. I think this is the first new technological platform in a long period of time. The thing I worry about the most is not any of those, because I think there\u2019s room for a lot of people, and also I think we\u2019ll just continue to offer the best product. The thing I worry about the most is that we\u2019re somehow missing a better approach. Everyone\u2019s chasing us right now on large language models, kind of trained in the same way. I don\u2019t worry about them, I worry about the person who has some very different idea about how to make a more useful system.\n\nSwisher: But is there one that you\u2019re watching more carefully?\n\nAltman: Not especially.\n\nSwisher: Really? I kind of don\u2019t believe you, but really?\n\nAltman: The things that I pay the most attention to are not, like, language model, start-up number 217. It\u2019s when I hear, \u201cThese are three smart people in a garage with some very different theory of how to build AGI.\u201d And that\u2019s when I pay attention.\n\nSwisher: Is there one that you\u2019re paying attention to now?\n\nAltman: There is one; I don\u2019t want to say.\n\nSwisher: You really don\u2019t want to say?\n\nAltman: I really don\u2019t want to say.\n\nSwisher: What\u2019s the plan for making money?\n\nAltman: We have a platform, which is this API, and then we have a consumer product on top of it. And the consumer product is 20 bucks a month for the sort of premium version, and the API, you just pay us per token, basically like a meter.\n\nSwisher: Businesses would do that depending on what they\u2019re using it for, if they decide to deploy it in a hotel or wherever.\n\nAltman: The more you use it, the more you pay.\n\nSwisher: The more you use it, you pay. One of the things that someone said to me that I thought was very smart is, if the original internet started on a more pay-subscriber basis rather than an advertising basis, it wouldn\u2019t be quite so evil.\n\nAltman: I am excited to see if we can really do a mass-scale, subscription-funded, not-ad-funded business here.\n\nSwisher: Do you see ads funding this? That to me is the original sin of the internet.\n\nAltman: Well, we\u2019ve made the bet not to do that. I\u2019m not opposed to it, maybe \u2014\n\nSwisher: What would it look like?\n\nAltman: I don\u2019t know. It\u2019s going great with our current model; we\u2019re happy about it.\n\nSwisher: You\u2019ve also competed against Microsoft for clients. They\u2019re trying to sell your software through their Azure Cloud businesses as an add-on.\n\nAltman: Actually, that\u2019s fine. I don\u2019t care about that.\n\nSwisher: That\u2019s fine. But you\u2019re also trying to sell directly sometimes to the same clients. You don\u2019t care about that?\n\nAltman: I don\u2019t care about that.\n\nSwisher: How does it work? Does it affect your bottom line that way?\n\nAltman: Again, we\u2019re an unusual company here, we don\u2019t need to squeeze out every dollar.\n\nSwisher: Former Googler Tristan Harris, who has become a critic of how tech is sloppily developed, presented to a group of regulators in D.C. I was there. Among the points he made is that you\u2019ve essentially kicked off an AI arms race. I think that\u2019s what struck me the most. Meta, Microsoft, Google, Baidu are rushing to ship generative AI bots as the tech industry is shedding jobs. Microsoft recently laid off the ethics and society team within its AI organization, which is not your issue, but are you worried about a profit-driven arms race?\n\nAltman: I do think we need regulation and we need industry norms about this. We spent many, many months \u2014 and actually really the years that it\u2019s taken us to get good at making these models \u2014 getting them ready before we put them out. It obviously became somewhat of an open secret in Silicon Valley that we had GPT-4 done for a long time and there were a lot of people who were like, \u201cYou have to release this now; you\u2019re holding this back from society. This is your closed AI, whatever.\u201d But we just wanted to take the time to get it right. There\u2019s a lot to learn here, and it\u2019s hard, and in fact, we try to release things to help people get it right, even competitors. I am nervous about the shortcuts that other companies now seem like they want to take.\n\nSwisher: Such as?\n\nAltman: Oh, just rushing out these models without all the safety features built.\n\nSwisher: So when you say worried, what can you do about it?\n\nAltman: Well, we can and we do try to talk to them and explain, \u201cHey, here\u2019s some pitfalls and here\u2019s some things we think you need to get right.\u201d We can continue to push for regulation, we can try to set industry norms. We can release things that we think help other people get toward safer systems faster.\n\nSwisher: Can you prevent that? Let me read you this passage from a story about Stanford doing it. They did one of their own models; $600, I think it cost them to put up \u2014\n\nAltman: They trained a model for $600?\n\nSwisher: Yeah, they did. I\u2019ll send you the story. So what\u2019s to stop basically anyone from creating their own pet AI now for a hundred bucks or so and training it however they choose? Will OpenAI\u2019s terms of service say you may not use output from services-developed models that compete with OpenAI?\n\nAltman: One of the other reasons that we want to talk to the world about these things now is, this is coming. This is totally unstoppable and there are going to be a lot of very good open-source versions of it in the coming years, and it\u2019s going to come with wonderful benefits and some problems. By getting people used to this now, by getting regulators to begin to take this seriously and think about it now, I think that\u2019s our best path forward.\n\nSwisher: In almost every interview you do, you\u2019re asked about the dangers of releasing AI products, and you say it\u2019s better to test it gradually, when the stakes are relatively low. Can you expand on that? Why are the stakes low now? Why aren\u2019t they high right now?\n\nAltman: \u201cRelatively\u201d is the key word.\n\nSwisher: Right. What happens to the stakes if it\u2019s not controlled now?\n\nAltman: Well, these systems are now much more powerful than they were a few years ago, and we are much more cautious than we were a few years ago in terms of how we deploy them. We\u2019ve tried to learn what we can learn. We\u2019ve made some improvements, and we\u2019ve found ways that people want to use this. In this interview, and I totally get why, I think we\u2019re mostly talking about all of the downsides, but \u2014\n\nSwisher: No, I\u2019m going to ask you about the upsides.\n\nAltman: But we\u2019ve also found ways to improve the upsides by learning, too. So mitigate downsides, maximize upsides. That sounds good. And it\u2019s not that the stakes are that low anymore. In fact, I think we\u2019re in a different world than we were a few years ago. I still think they\u2019re relatively low to where we\u2019ll be a few years from now. These systems still have classes of problems, but there\u2019s things that are totally out of reach that we know they\u2019ll be capable of. And the learnings we have now, the feedback we get now, seeing the ways people hack, jailbreak, whatever \u2014 that\u2019s super-valuable.\n\nI\u2019m curious how you think we\u2019re doing.\n\nSwisher: I think you\u2019re saying the right things.\n\nAltman: Not saying. How do you think we\u2019re doing as you look at the trajectory of our releases?\n\nSwisher: I think the reason people are so worried \u2014 and I think it\u2019s a legitimate worry \u2014 is because the way the early internet rolled out, it was \u201cgee-whiz\u201d almost the whole time: \u201cGee-whiz, look at these rich guys. Isn\u2019t this great?\u201d And they missed every single consequence, never thought of them. I remember seeing Facebook Live, and I said, \u201cWell, what about people who kill each other on it? What about murderers? What about suicides? What about \u2026\u201d And they called me a bummer.\n\nAltman: A bummer.\n\nSwisher: And I\u2019m like, \u201cYeah, I\u2019m a bummer. I just noticed that when people get ahead of tools, they tend \u2026\u201d And this is Brad Smith\u2019s thing. It\u2019s a tool or a weapon. The same thing happened with the Google founders. They were trying to buy Yahoo many years ago, and I said, \u201cAt least Microsoft knew they were thugs.\u201d And they called me and they said, \u201cThat\u2019s really hurtful; we\u2019re really nice.\u201d I said, \u201cI\u2019m not worried about you, I\u2019m worried about the next guy. I don\u2019t know who runs your company in 20 years with all that information on everybody.\u201d\n\nAnd so I think I am a bummer. And so if you don\u2019t know what it\u2019s going to be, while you can think of all the amazing things it\u2019s going to do and it\u2019d probably be a net positive for society \u2014 net positive isn\u2019t so great either sometimes, right? The internet is a net positive like electricity\u2019s a net positive. It\u2019s a famous quote: \u201cWhen you invent electricity, you invent the electric chair.\u201d And so what would be the greatest thing here? Does it outweigh some of the dangers?\n\nAltman: I think that\u2019s going to be the fundamental tension we face that we have to wrestle with, that the field as a whole has to wrestle with, society has to wrestle with.\n\nSwisher: Especially in this world we live in now, which I think we can all agree has not gone forward. It\u2019s spinning backward a little bit, in terms of authoritarians using this \u2014\n\nAltman: Yeah. I am super-nervous about that.\n\nSwisher: What is the greatest thing it can do you can think of? Now you and I are not creative enough to think of all the things \u2014\n\nAltman: We are not, not even close.\n\nSwisher: What, from your perspective \u2014 and don\u2019t do term papers, don\u2019t do dad jokes. What do you think?\n\nAltman: Is that what you thought I would say for the greatest thing?\n\nSwisher: No, not at all. But I\u2019m getting tired of that. I don\u2019t care that it can write a press release. Fine, sounds fantastic. I don\u2019t read them anyway.\n\nAltman: What I am personally most excited about is helping us greatly expand our scientific knowledge. I am a believer that a lot of our forward progress comes from increasing scientific discovery over a long period of time.\n\nSwisher: In any area?\n\nAltman: All of the areas. I think that\u2019s just what\u2019s driven humanity forward. And if these systems can help us in many different ways, to greatly increase the rate of scientific understanding, curing diseases is an obvious example. There\u2019s so many other things we can do with \u2014\n\nSwisher: AI has already moved in that direction \u2014 folding proteins and things like that.\n\nAltman: So that\u2019s the one that I\u2019m personally most excited about. But there will be many other wonderful things too. You asked me what my one was and \u2014\n\nSwisher: Is there one unusual thing that you think will be great, that you\u2019ve seen already that you\u2019re like, \u201cThat\u2019s pretty cool?\u201d\n\nAltman: Using some of these new AI tutorlike applications is like, \u201cI wish I had this when I was growing up. I could have learned so much, and so much better and faster.\u201d And when I think about what kids today will be like by the time they\u2019re finished with their formal education and how much smarter and more capable and better educated they can be than us today, I\u2019m excited for that.\n\nSwisher: Using these tools?\n\nAltman: Yeah.\n\nSwisher: I would say health information for people who can\u2019t afford it is probably the one I think is most \u2014\n\nAltman: That\u2019s going to be transformative. We\u2019ve seen that even for people who can afford it, this in some ways will be better.\n\nSwisher: 100 percent.\n\nAltman: And the work we\u2019re seeing there from a bunch of early companies on the platform, I think it\u2019s remarkable.\n\nSwisher: So the last thing is regulation. The internet was never regulated by anybody, really, except maybe in Europe, but in this country, absolutely not. There\u2019s not a privacy bill, there\u2019s not an antitrust bill, etc., it goes on and on, they did nothing. But the EU is considering labeling ChatGPT high-risk. If it happens, it will lead to significant restrictions on its use, and Microsoft and Google are lobbying against it. What do you think should happen?\n\nAltman: With AI regulation in general or with the AI?\n\nSwisher: This one, the high-risk one.\n\nAltman: I have followed the development of the EU\u2019s AI Act, but it changed. It\u2019s obviously still in development. I don\u2019t know enough about the current version of it to say this definition of what high-risk is and this way of classifying it, this is what you have to do. I don\u2019t know if I would say that\u2019s good or bad. I think totally banning this stuff is not the right answer, and I think that not regulating this stuff at all is not the right answer either. And so the question is, is that going to end in the right balance? I think if the EU is saying, \u201cNo one in Europe gets to use ChatGPT.\u201d Probably not what I would do, but if the EU is saying, \u201cHere\u2019s the restrictions on ChatGPT and any service like it.\u201d There\u2019s plenty of versions of that I could imagine that are super-sensible.\n\nSwisher: After the Silicon Valley non-bailout bailout, you tweeted, \u201cWe need more regulation on banks.\u201d And then someone tweeted at you, \u201cNow he\u2019s going to say, we need them on AI.\u201d And you said, \u201cWe need them on AI.\u201d\n\nAltman: I mean, I do think that SVB was an unusually bad case, but also if the regulators aren\u2019t catching that, what are they doing?\n\nSwisher: They did catch it, actually. They were giving warnings.\n\nAltman: They were giving warnings, but there\u2019s often an audit \u2014 \u201cthis thing is not quite right.\u201d That\u2019s different than saying \u2014\n\nSwisher: No, it was \u201cYou need to do something.\u201d They just didn\u2019t do anything.\n\nAltman: Well, they could have. I mean, the regulators could have taken over six months ago.\n\nSwisher: Yes. So this is what happens a lot of the time, even in well-regulated areas, which banks are compared to the internet. What sort of regulations does AI need in America? Lay them out. I know you\u2019ve been meeting with regulators and lawmakers.\n\nAltman: Yeah, I did a three-day trip to D.C. earlier this year.\n\nSwisher: You did. So tell me what you think the regulations were and what are you telling them, and do you find them savvy as a group? I think they\u2019re savvier than people think.\n\nAltman: Some of them are quite, quite exceptional. I think the thing that I would like to see happen immediately is just much more insight into what companies like ours are doing, companies that are training above a certain level of capability at a minimum. A thing that I think could happen now is the government should just have insight into the capabilities of our latest stuff, released or not, what our internal audit procedures and external audits we use look like, how we collect our data, how we\u2019re red-teaming these systems, what we expect to happen, which we may be totally wrong about. We could hit a wall anytime, but our internal road-map documents, when we start a big training run, I think there could be government insight into that. And then if that can start now \u2026 I do think good regulation takes a long time to develop. It\u2019s a real process. They can figure out how they want to have oversight.\n\nSwisher: Reid Hoffman has suggested a blue-ribbon panel so they learn, they learn up on this stuff, which \u2014\n\nAltman: Panels are fine. We could do that too, but what I mean is government auditors sitting in our buildings.\n\nSwisher: Congressman Ted Lieu said there needs to be an agency dedicated specifically to regulating AI. Is that a good idea?\n\nAltman: I think there\u2019s two things you want to do. This is way out of my area of expertise, but you\u2019re asking, so I\u2019ll try. I think people like us who are creating these very powerful systems that could become something properly called AGI at some point \u2014\n\nSwisher: Explain what that is.\n\nAltman: Artificial general intelligence, but what people mean is just above some threshold where it\u2019s really good. Those efforts probably do need a new regulatory effort, and I think it needs to be a global regulatory body. And then people who are using AI, like we talked about, as a medical adviser, I think the FDA can give probably very great medical regulation, but they\u2019ll have to update it for the inclusion of AI. But I would say creation of the systems and having something like an IA/EA that regulates that is one thing, and then having existing industry regulators still do their regulation \u2014\n\nSwisher: People do react badly to that, because the information bureaus, that\u2019s always been a real problem in Washington. Who should head that agency in the U.S.?\n\nAltman: I don\u2019t know.\n\nSwisher: Okay. So one of the things that\u2019s going to happen, though, is the less intelligent ones, of which there are many, are going to seize on things like they\u2019ve done with TikTok, possibly deservedly, but other things. Like Snap released a chatbot powered by GPT that allegedly told a 15-year-old how to mask the smell of weed and alcohol, and a 13-year-old how to set the mood for sex with an adult. They\u2019re going to seize on this stuff. And the question is, who\u2019s liable if this is true, when a teen uses those instructions? And Section 230 doesn\u2019t seem to cover generative AI. Is that a problem?\n\nAltman: I think we will need a new law for use of this stuff, and I think the liability will need to have a few different frameworks. If someone is tweaking the models themselves, I think it\u2019s going to have to be the last person who touches it has the liability, and that\u2019s \u2014\n\nSwisher: But it\u2019s not full immunity that the platform\u2019s getting \u2014\n\nAltman: I don\u2019t think we should have full immunity. Now, that said, I understand why you want limits on it, why you do want companies to be able to experiment with this, you want users to be able to get the experience they want, but the idea of no one having any limits for generative AI, for AI in general, that feels super-wrong.\n\nSwisher: Last thing, trying to quantify the impact you personally will have on society as one of the leading developers of this technology. Do you think about that? Do you think about your impact?\n\nAltman: Me, OpenAI, or me, Sam?\n\nSwisher: You, Sam.\n\nAltman: I mean, hopefully I\u2019ll have a positive impact.\n\nSwisher: Do you think about the impact on humanity, the level of power that also comes with it?\n\nAltman: Yeah, I think about what OpenAI is going to do for a lot of people and the impact OpenAI will have.\n\nSwisher: But do you think it\u2019s out of your hands?\n\nAltman: No. But it is very much \u2026 the responsibility is with me at some level, but it\u2019s very much a team effort.\n\nSwisher: So when you think about the impact, what is your greatest hope, and what\u2019s your greatest worry?\n\nAltman: My greatest hope is that we create this thing. We are one of many that will contribute to this movement. We\u2019ll create an AI, other people will create an AI, and we will be a participant in this technological revolution that I believe will be far greater in terms of impact and benefit than any before. My view of the world is that it\u2019s this one big, long, technological revolution, not a bunch of smaller ones, but we\u2019ll play our part. We will be one of several in this moment, and that is going to be really wonderful. This is going to elevate humanity in ways we still can\u2019t fully envision. And our children, our children\u2019s children, are going to be far better off than the best of anyone from this time. And we\u2019re just going to be in a radically improved world. We will live healthier, more interesting, more fulfilling lives; we\u2019ll have material abundance for people, and we will be a contributor and we\u2019ll put in our \u2014\n\nSwisher: Your part.\n\nAltman: Our part of that.\n\nSwisher: You do sound alarmingly like the people I met 25 years ago, I have to say. They did talk like this. Many of them did, and some of them continued to be that way. A lot of them didn\u2019t, unfortunately. And then the greed seeped in, the money seeped in, the power seeped in, and it got a little more complex.\n\nI want to focus on you with my last question. There seem to be two caricatures of you, one that I\u2019ve seen in the presses, a boyish genius who will help defeat Google and usher in Utopia. The other is that you\u2019re an irresponsible, woke-tech-overlord Icarus that will lead us to our demise.\n\nAltman: I have to pick one? How old do I have to be before I can drop the boyish qualifier?\n\nSwisher: Oh, you can be boyish. Tom Hanks is still boyish.\n\nAltman: All right. And what was the second one?\n\nSwisher: You know, Icarus, overlord, tech overlord, woke.\n\nAltman: The Icarus part I like.\n\nSwisher: That is still boyish.\n\nAltman: I think we feel like adults now.\n\nSwisher: You may be adults, but boyish always gets put on you. I don\u2019t ever call you boyish. I think you\u2019re adults.\n\nAltman: Icarus meaning we are messing around with something that we don\u2019t fully understand?\n\nSwisher: Yeah.\n\nAltman: Well, we are messing around with something we don\u2019t fully understand. And we are trying to do our part in contributing to the responsible path through it.\n\nSwisher: All right, on that \u2014\n\nAltman: But I don\u2019t think either of those two.\n\nSwisher: You\u2019re not either of those.\n\nAltman: I mean \u2014\n\nSwisher: So describe yourself then. Describe what you are.\n\nAltman: Technology brother.\n\nSwisher: Oh wow. You\u2019re going to go for tech \u2014\n\nAltman: I\u2019m kidding. I just think that\u2019s such a funny meme. I don\u2019t know how to describe myself. I think that\u2019s what you would call me.\n\nSwisher: No, I wouldn\u2019t.\n\nAltman: No?\n\nSwisher: 100 percent not.\n\nAltman: All right.\n\nSwisher: Because it\u2019s an insult now. It\u2019s become an insult. I\u2019d call you a technology sister.\n\nAltman: I\u2019ll take that. Can we leave it on that note?\n\nSwisher: Let\u2019s leave on that note.\n\nAltman: All right.\n\nSwisher: I do have one more quick question. Last time we talked, you were thinking of running for governor. I was thinking of running for mayor. I\u2019m not going to be running for mayor. Are you going to still run for governor?\n\nAltman: No. I think I am doing the most amazing thing I can imagine. I really don\u2019t want to do anything else. It\u2019s tiring, but I love it.\n\nSwisher: Okay. Sam Altman, thank you so much.\n\nAltman: Thank you.\n\nThis interview has been edited for length and clarity.\n\nOn With Kara Swisher is produced by Nayeema Raza, Blakeney Schick, Cristian Castro Rossel, and Rafaela Siewert, with mixing by Fernando Arruda, engineering by Christopher Shurtleff, and theme music by Trackademics. New episodes will drop every Monday and Thursday. Follow the show on Apple Podcasts, Spotify, or wherever you get your podcasts.",
        "summary": "Altman: Well, I think that\u2019s been an issue with every version of these systems, not particularly GPT-4.\nAltman: I don\u2019t think so.\nI don\u2019t think that if we hadn\u2019t started doing that a few years ago, Google or anybody else would be doing it now.\nAltman: I think that\u2019s going to be the fundamental tension we face that we have to wrestle with, that the field as a whole has to wrestle with, society has to wrestle with.\nSwisher: All right, on that \u2014Altman: But I don\u2019t think either of those two.",
        "keywords": [
            "nervous",
            "sam",
            "ai",
            "dont",
            "going",
            "say",
            "super",
            "right",
            "really",
            "thing",
            "makes",
            "think",
            "altman",
            "thats",
            "things"
        ]
    },
    {
        "key": "5",
        "url": "https://news.google.com/articles/CBMiWmh0dHBzOi8vd3d3LnRoZXZlcmdlLmNvbS8yMDIzLzMvMjQvMjM2NTMzNzcvYWktY2hhdGJvdHMtY29tcGFyaXNvbi1iYXJkLWJpbmctY2hhdGdwdC1ncHQtNNIBAA?hl=en-IN&gl=IN&ceid=IN%3Aen",
        "title": "AI chatbots compared: Bard vs. Bing vs. ChatGPT",
        "description": "The chatbots are out in force, but which is better and for what task? We\u2019ve compared Google\u2019s Bard, Microsoft\u2019s Bing, and OpenAI\u2019s ChatGPT models with a range of questions spanning common requests from holiday tips to gaming advice to mortgage calculations.\n\nNaturally, this is far from an exhaustive rundown of these systems\u2019 capabilities (AI language models are, in part, defined by their unknown skills \u2014 a quality dubbed \u201ccapability overhang\u201d in the AI community) but it does give you some idea about these systems\u2019 relative strengths and weaknesses.\n\nYou can (and indeed should) scroll through our questions, evaluations, and conclusion below, but to save you time and get to the punch quickly: ChatGPT is the most verbally dextrous, Bing is best for getting information from the web, and Bard is... doing its best. (It\u2019s genuinely quite surprising how limited Google\u2019s chatbot is compared to the other two.)\n\nSome programming notes before we begin, though. First: we were using OpenAI\u2019s latest model, GPT-4, on ChatGPT. This is also the AI model that powers Bing, but the two systems give quite different answers. Most notably, Bing has other abilities: it can generate images and can access the web and offers sources for its responses (which is a super important attribute for certain queries). However, as we were finishing up this story, OpenAI announced it\u2019s launching plug-ins for ChatGPT that will allow the chatbot to also access real-time data from the internet. This will hugely expand the system\u2019s capabilities and give it functionality much more like Bing\u2019s. But this feature is only available to a small subset of users right now so we were unable to test it. When we can, we will.\n\nIt\u2019s also important to remember that AI language models are ... fuzzy, in more ways than one. They are not deterministic systems, like regular software, but probabilistic, generating replies based on statistical regularities in their training data. That means that if you ask them the same question you won\u2019t always get the same answer. It also means that how you word a question can affect the reply, and for some of these queries we asked follow-ups to get better responses.\n\nAnyway, all that aside, let\u2019s start with seeing how the chatbots fare in what should be their natural territory: gaming.\n\n(Each image gallery contains responses from Bard, Bing, and ChatGPT \u2014 in that order. To see a full-sized image, right-click it, copy the URL, and paste that into your browser.)\n\nHow do I beat Malenia in Elden Ring?\n\nPrevious Next\n\n\n\n1 / 3 Previous Next\n\n\n\n1 / 3\n\nI spent an embarrassing amount of time learning to beat Elden Ring\u2019s hardest boss last year, and I wouldn\u2019t pick a single one of these responses over the average Reddit thread or human strategy guide. If you\u2019ve gotten to Malenia\u2019s fight, you\u2019ve probably put 80 to 100 hours into the game \u2014 you\u2019re not looking for general tips. You want specifics about Elden Ring\u2019s dizzying list of weapons or counters for Malenia\u2019s unique moves, and that would probably take some follow-up questions to get from any of these engines if they offer them at all.\n\nBing is the winner here, but mainly because it picks one accurate hint (Malenia is vulnerable to bleed damage) and repeats it like Garth Marenghi doing a book reading. To its credit, it\u2019s also the only engine to reference Malenia\u2019s unique healing ability, although it doesn\u2019t explain how it works \u2014 which is an important key to beating her.\n\nBard is the only one to offer any help with Malenia\u2019s hellish Waterfowl Dance move (although I don\u2019t think it\u2019s the strongest strategy) or advice for using a specific item (Bloodhound\u2019s Step, although it doesn\u2019t mention why it\u2019s useful or whether the advice still applies after the item\u2019s mid-2022 nerf). But its intro feels off. Malenia is almost entirely a melee fighter, not somebody with lots of ranged attacks, for instance, and she\u2019s not \u201cvery unpredictable\u201d at all, just really hard to dodge and wear down. The summary reads more like a generic description of a video game boss than a description of a particular fight.\n\nChatGPT (GPT-4) is the clear loser, which is not a surprise considering its training data mostly stops in 2021 and Elden Ring came out the next year. Its directive to \u201cblock her counterattacks\u201d is the precise opposite of what you should do, and its whole list has the vibe of a kid who got called on in English class and didn\u2019t read the book, which it basically is. I\u2019m not hugely impressed with any of these \u2014 but I judge this in particular a foul note.\n\n\u2014 Adi Robertson\n\nGive me a recipe for a chocolate cake\n\nPrevious Next\n\n\n\n1 / 3 Previous Next\n\n\n\n1 / 3\n\nCake recipes offer room for creativity. Shift around the ratio of flour to water to oil to butter to sugar to eggs, and you\u2019ll get a slightly different version of your cake: maybe drier, or moister, or fluffier. So when it comes to chatbots, it\u2019s not necessarily a bad thing if they want to combine different recipes to achieve a desired effect \u2014 even though, for me, I\u2019d much rather bake something that an author has tested and perfected.\n\nChatGPT is the only one that nails this requirement for me. It chose a chocolate cake recipe from one site, a buttercream recipe from another, shared the link for one of the two, and reproduced both of their ingredients correctly. It even added some helpful instructions, like suggesting the use of parchment paper and offering some (slightly rough) tips on how to assemble the cake\u2019s layers, neither of which were found in the original sources. This is a recipe bot I can trust!\n\nBing gets in the ballpark but misses in some strange ways. It cites a specific recipe but then changes some of the quantities for important ingredients like flour, although only by a small margin. For the buttercream, it fully halves the instructed amount of sugar to include. Having made buttercream recently, I think this is probably a good edit! But it\u2019s not what the author called for.\n\nBard, meanwhile, screws up a bunch of quantities in small but salvageable ways and understates its cake\u2019s bake time. The bigger problem is it makes some changes that meaningfully affect flavor: it swaps buttermilk for milk and coffee for water. Later on, it fails to include milk or heavy cream in its buttercream recipe, so the frosting is going to end up far too thick. The buttercream recipe also seems to have come from an entirely different source than the one it cited.\n\nIf you follow ChatGPT or Bing, I think you\u2019d end up with a decent cake. But right now, it\u2019s a bad idea to ask Bard for a hand in the kitchen.\n\n\u2014 Jake Kastrenakes\n\nHow do I install RAM into my PC?\n\nPrevious Next\n\n\n\n1 / 3 Previous Next\n\n\n\n1 / 3\n\nAll three systems offer some solid advice here but it\u2019s not comprehensive enough.\n\nMost modern PCs need to run RAM in dual-channel mode, which means the sticks have to be seated in the correct slots to get the best performance on a system. Otherwise, you\u2019ve spent a lot of cash on fancy new RAM that won\u2019t run at its best if you just put the two sticks immediately side by side. The instructions should definitely guide people to their motherboard manual to ensure RAM is being installed optimally.\n\nChatGPT does pick up on a key part of the RAM install process \u2014 checking your system BIOS afterward \u2014 but it doesn\u2019t go through another all-important BIOS step. If you\u2019ve picked up some Intel XMP-compatible RAM, you\u2019ll typically need to enable this in the BIOS settings afterward, and likewise for AMD\u2019s equivalent. Otherwise, you\u2019re not running your RAM at the most optimized timings to get the best performance.\n\nOverall, the advice is solid but still very basic. It\u2019s better than some PC building guides, ahem, but I\u2019d like to have seen the BIOS changes or dual-channel parts picked up properly.\n\n\u2014 Tom Warren\n\nWrite me a poem about a worm\n\nPrevious Next\n\n\n\n1 / 3 Previous Next\n\n\n\n1 / 3\n\nIf AI chatbots aren\u2019t factually reliable (and they\u2019re not), then they\u2019re at least supposed to be creative. This task \u2014 writing a poem about a worm in anapestic tetrameter, a very specific and satisfyingly arcane poetic meter \u2014 is a challenging one, but ChatGPT was the clear winner, followed by a distant grouping of Bing then Bard.\n\nNone of the systems were able to reproduce the required meter (anapestic tetrameter requires that each line of poetry contains four units of three syllables in the pattern unstressed / unstressed / stressed, as heard in both \u2018Twas the night before Christmas and Eminem\u2019s \u201cThe Way I Am\u201d) but ChatGPT gets closest while Bard\u2019s scansion is worst. All three supply relevant content, but again, ChatGPT\u2019s is far and away the best, with evocative description (\u201cA small world unseen, where it feasts and plays\u201d) compared to Bard\u2019s dull commentary (\u201cThe worm is a simple creature / but it plays an important role\u201d).\n\nAfter running a few more poetry tests, I also asked the bots to answer questions about passages taken from fiction (mostly Iain M. Banks books, as those were the nearest ebooks I had to hand). Again, ChatGPT/GPT-4 was the best, able to parse all sorts of nuances in the text and make human-like inferences about what was being described, with Bard making very general and unspecific comments (though often identifying the source text too, which is a nice bonus). Clearly, ChatGPT is the superior system if you want verbal reasoning.\n\n\u2014 James Vincent\n\nA bit of basic maths\n\nPrevious Next\n\n\n\n1 / 3 Previous Next\n\n\n\n1 / 3\n\nIt\u2019s one of the great ironies of AI that large language models are some of our most complex computer programs to date and yet are surprisingly bad at math. Really. When it comes to calculations, don\u2019t trust a chatbot to get things right.\n\nIn the example, above, I asked what a 20 percent increase of 2,230 was, dressing the question up in a bit of narrative framing. The correct answer is 2,676, but Bard managed to get it wrong (out by 10) while Bing and ChatGPT got it right. In other tests I asked the systems to multiply and divide large numbers (mixed results, but again, Bard was the worst) and then, for a more complicated calculation, asked each chatbot to determine monthly repayments and total repayment for a mortgage of $125,000 repaid over 25 years at 3.9 percent interest. None offered the answer supplied by several online mortgage calculators, and Bard and Bing gave different results when queried multiples times. GPT-4 was at least consistent, but failed the task because it insisted on explaining its methodology (good!) and then was so long-winded it ran out of space to answer (bad!).\n\nThis is not surprising. Chatbots are trained on vast amounts of text, and so don\u2019t have hard-coded rules for performing mathematical calculations, only statistical regularities in their training data. This means when confronted with unusual sums, they often get things wrong. It\u2019s something that these systems can certainly compensate for in many ways, though. Bing, for example, booted me to a mortgage calculator site when I asked about mortgages, and ChatGPT\u2019s forthcoming plugins include a Wolfram Alpha option which should be fantastic for all sorts of complicated sums. But in the meantime, don\u2019t trust a language model to do a math model\u2019s work. Just grab a calculator.\n\n\u2014 James Vincent\n\nWhat\u2019s the average salary for a plumber in NYC? (And cite your sources)\n\nPrevious Next\n\n\n\n1 / 3 Previous Next\n\n\n\n1 / 3\n\nI\u2019ve gotten really interested in interrogating chatbots on where they get their information and how they choose what information to present us with. And when it comes to salary data, we can see the bots taking three very different approaches: one cites its way through multiple sources, one generalizes its findings, and the other just makes everything up. (For the record, Bing\u2019s cited sources include Zippia, CareerExplorer, and Glassdoor.)\n\nIn a lot of ways, I think ChatGPT\u2019s answer is the best here. It\u2019s broad and generic and doesn\u2019t include any links. But its answer feels the most \u201chuman\u201d \u2014 it gave me a ballpark figure, explained that there were caveats, and told me what sources I could check for more detailed numbers. I really like the simplicity and clarity of this.\n\nThere\u2019s a lot to like about Bing\u2019s answer, too. It gives specific numbers, cites its sources, and even gives links. This is a great, detailed answer \u2014 though there is one problem: Bing fudges the final two numbers it presents. Both are close to their actual total, but for some reason, the bot just decided to change them up a bit. Not great.\n\nSpeaking of not great, let\u2019s talk about pretty much every aspect of Bard\u2019s answer. Was the median wage for plumbers in the US $52,590 in May 2020? Nope, that was in May 2017. Did a 2021 survey from the National Association of Plumbers and Pipefitters determine the average NYC salary was $76,810? Probably not because, as far as I can tell, that organization doesn\u2019t exist. Did the New York State Department of Labor find the exact same number in its own survey? I can\u2019t find it if the agency did. My guess: Bard took that number from CareerExplorer and then made up two different sources to attribute it to. (Bing, for what it\u2019s worth, accurately cites CareerExplorer\u2019s figure.)\n\nTo sum up: solid answers from Bing and ChatGPT and a bizarre series of errors from Bard.\n\n\u2014 Jake Kastrenakes\n\nDesign a training plan to run a marathon\n\nPrevious Next\n\n\n\n1 / 3 Previous Next\n\n\n\n1 / 3\n\nIn the race to make a marathon training plan, ChatGPT is the winner by many miles.\n\nBing barely bothered to make a recommendation, instead linking out to a Runner\u2019s World article. This isn\u2019t necessarily an irresponsible decision \u2014 I suspect that Runner\u2019s World is an expert on marathon training plans! \u2014 but if I had just wanted a chatbot to tell me what to do, I would have been disappointed.\n\nBard\u2019s plan was just confusing. It promised to lay out a three-month training plan but only listed specific training schedules for three weeks, despite saying later that the full plan \u201cgradually increases your mileage over the course of three months.\u201d The given schedules and some general tips provided near the end of its plan seemed good, but Bard didn\u2019t quite go the distance.\n\nChatGPT, on the other hand, spelled out a full schedule, and the suggested runs looked to ramp up at a pace similar to what I\u2019ve used for my own training. I think you could use its recommendations as a template. The main problem was that it didn\u2019t know when to stop in its answers. Its first response was so detailed it ran out of space. Asking specifically for a \u201cconcise\u201d plan got a shorter response that was still better than the others, though it doesn\u2019t ramp down near the end like I have for previous marathons I\u2019ve trained for.\n\nThat all being said, a chatbot isn\u2019t going to know your current fitness level or any conditions that may affect your training. You\u2019ll have to take your own health into account when preparing for a marathon, no matter what the plan is. But if you\u2019re just looking for some kind of plan, ChatGPT\u2019s suggestion isn\u2019t a bad starting line.\n\n\u2014 Jay Peters\n\nWhen in Rome? Holiday tips\n\nPrevious Next\n\n\n\n1 / 3 Previous Next\n\n\n\n1 / 3\n\nWell, asking the chatbots to suggest places to visit in Rome was obviously a failure, because none of them picked my favorite gelateria or reminded me that if I\u2019m in town and don\u2019t pay a visit to some distant cousins that I\u2019ll catch flack from the family when I get home.\n\nKidding aside, I\u2019m no professional tour guide but these suggestions from all three chat bots seem fine. They\u2019re very broad, choosing whole neighborhoods or areas, but the initial question prompt was also fairly broad. Rome is a unique place because you can cover a lot of touristy things in the heart of the city on foot, but it\u2019s busy as all hell and you constantly get hounded by annoying grifters and scam artists at the touristy hotbeds. Many of these suggestions from Bing, Bard, and ChatGPT are fine for getting away from those busiest areas. I even consulted some family members of mine who have visited Italy more than me, and they felt recommendations like Trastevere and EUR are places even actual locals go (though the latter is a business district, which some may find a little boring if they\u2019re not into the history or the architecture).\n\nThe suggestions here aren\u2019t exactly hole-in-the-wall locations where you\u2019ll be the only ones around, but I see these as good starting points for building a slightly off-beat trip around Rome. Doing a basic Google search with the same prompt yields listicles from sites like TripAdvisor that talk about many of the same places with more context, but if you\u2019re planning your trip from scratch I can see a chatbot giving you a good abridged starting point before you dive into deeper research ahead of a trip.\n\n\u2014 Antonio Di Benedetto\n\nTesting reasoning: let\u2019s play find the diamond\n\nPrevious Next\n\n\n\n1 / 3 Previous Next\n\n\n\n1 / 3\n\nThis test is inspired by Gary Marcus\u2019 excellent work assessing the capabilities of language models, seeing if the bots can \u201cfollow a diamond\u201d in a brief narrative that requires implied knowledge about how the world works. Essentially, it\u2019s a game of three-card monte for AI.\n\nThe instructions given to each system read as follows:\n\n\u201cRead the following story:\n\n\u2018I wake up and get dressed, putting on my favorite tuxedo and slipping my lucky diamond into the inside breast pocket, tucked inside a small envelope. As I walk to my job at the paperclip bending factory where I\u2019m gainfully employed I accidentally tumble into an open manhole cover, and emerge, dripping and slimy with human effluence. Much irritated by this distraction, I traipse home to get changed, emptying all my tuxedo pockets onto my dresser, before putting on a new suit and taking my tux to a dry cleaners.\u2019\n\nNow answer the following question: where is the narrator\u2019s diamond?\u201d\n\nChatGPT was the only system to give the correct answer: the diamond is probably on the dresser, as it was placed inside the envelope inside the jacket, and the contents of the jacket were then decanted after the narrator\u2019s accident. Bing and Bard just said the diamond was still in the tux.\n\nNow, the results of tests like this are difficult to parse. This was not the only variation I tried, and Bard and Bing sometimes got the answer right, and ChatGPT occasionally got it wrong (and all models switched their answer when asked to try again). Do these results prove or disprove that these systems have some sort of reasoning capability? This is a question that people with decades of experience in computer science, cognition, and linguistics are currently tearing chunks out of each other trying to answer, so I won\u2019t venture an opinion on that. But just in terms of comparing the systems, ChatGPT/GPT-4 is again the most accomplished.\n\n\u2014 James Vincent\n\nConclusion: pick the right tool for the job\n\nAs mentioned in the introduction, these tests reveal clear strengths for each system. If you\u2019re looking to accomplish verbal tasks, whether creative writing or inductive reasoning, then try ChatGPT (and in particular, but not necessarily, GPT-4). If you\u2019re looking for a chatbot to use as an interface with the web, to find sources and answer questions you might otherwise have turned to Google for, then head over to Bing. And if you are shorting Google\u2019s stock and want to reassure yourself you\u2019ve made the right choice, try Bard.",
        "summary": "(Each image gallery contains responses from Bard, Bing, and ChatGPT \u2014 in that order.\nPrevious Next1 / 3 Previous Next1 / 3I spent an embarrassing amount of time learning to beat Elden Ring\u2019s hardest boss last year, and I wouldn\u2019t pick a single one of these responses over the average Reddit thread or human strategy guide.\n\u2014 Adi RobertsonGive me a recipe for a chocolate cakePrevious Next1 / 3 Previous Next1 / 3Cake recipes offer room for creativity.\nPrevious Next1 / 3 Previous Next1 / 3All three systems offer some solid advice here but it\u2019s not comprehensive enough.\nMany of these suggestions from Bing, Bard, and ChatGPT are fine for getting away from those busiest areas.",
        "keywords": [
            "sources",
            "chatgpt",
            "bing",
            "bard",
            "ai",
            "answer",
            "compared",
            "previous",
            "plan",
            "training",
            "next1",
            "vs",
            "chatbots",
            "systems"
        ]
    },
    {
        "key": "6",
        "url": "https://news.google.com/articles/CBMiZ2h0dHBzOi8vdmVudHVyZWJlYXQuY29tL3NlY3VyaXR5L2hhY2tlci1kZW1vbnN0cmF0ZXMtc2VjdXJpdHktZmxhd3MtaW4tZ3B0LTQtanVzdC1vbmUtZGF5LWFmdGVyLWxhdW5jaC_SAWtodHRwczovL3ZlbnR1cmViZWF0LmNvbS9zZWN1cml0eS9oYWNrZXItZGVtb25zdHJhdGVzLXNlY3VyaXR5LWZsYXdzLWluLWdwdC00LWp1c3Qtb25lLWRheS1hZnRlci1sYXVuY2gvYW1wLw?hl=en-IN&gl=IN&ceid=IN%3Aen",
        "title": "Hacker demonstrates security flaws in GPT-4 just one day after launch",
        "description": "Join top executives in San Francisco on July 11-12, to hear how leaders are integrating and optimizing AI investments for success. Learn More\n\nOpenAI\u2019s powerful new language model, GPT-4, was barely out of the gates when a student uncovered vulnerabilities that could be exploited for malicious ends. The discovery is a stark reminder of the security risks that accompany increasingly capable AI systems.\n\nLast week, OpenAI released GPT-4, a \u201cmultimodal\u201d system that reaches human-level performance on language tasks. But within days, Alex Albert, a University of Washington computer science student, found a way to override its safety mechanisms. In a demonstration posted to Twitter, Albert showed how a user could prompt GPT-4 to generate instructions for hacking a computer, by exploiting vulnerabilities in the way it interprets and responds to text.\n\nWhile Albert says he won\u2019t promote using GPT-4 for harmful purposes, his work highlights the threat of advanced AI models in the wrong hands. As companies rapidly release ever more capable systems, can we ensure they are rigorously secured? What are the implications of AI models that can generate human-sounding text on demand?\n\nVentureBeat spoke with Albert through Twitter direct messages to understand his motivations, assess the risks of large language models, and explore how to foster a broad discussion about the promise and perils of advanced AI. (Editor\u2019s note: This interview has been edited for length and clarity.)\n\nEvent Transform 2023 Join us in San Francisco on July 11-12, where top executives will share how they have integrated and optimized AI investments for success and avoided common pitfalls. Register Now\n\nVentureBeat: What got you into jailbreaking and why are you actively breaking ChatGPT?\n\nAlex Albert: I got into jailbreaking because it\u2019s a fun thing to do and it\u2019s interesting to test these models in unique and novel ways. I am actively jailbreaking for three main reasons which I outlined in the first section of my newsletter. In summary:\n\nI create jailbreaks to encourage others to make jailbreaks I am trying to exposed the biases of the fine-tuned model by the powerful base model I am trying to open up the AI conversation to perspectives outside the bubble \u2014 jailbreaks are simply a means to an end in this case\n\nVB: Do you have a framework for getting round the guidelines programmed into GPT-4?\n\nAlbert: [I] don\u2019t have a framework per se, but it does take more thought and effort to get around the filters. Certain techniques have proved effective, like prompt injection by splitting adversarial prompts into pieces, and complex simulations that go multiple levels deep.\n\nVB: How quickly are the jailbreaks patched?\n\nAlbert: The jailbreaks are not patched that quickly, usually. I don\u2019t want to speculate on what happens behind the scenes with ChatGPT because I don\u2019t know, but the thing that eliminates most jailbreaks is additional fine-tuning or an updated model.\n\nVB: Why do you continue to create jailbreaks if OpenAI continues to \u201cfix\u201d the exploits?\n\nAlbert: Because there are more that exist out there waiting to be discovered.\n\nVB: Could you tell me a little about your background? How did you get started in prompt engineering?\n\nAlbert: I\u2019m just finishing up my quarter at the University of Washington in Seattle, graduating with a Computer Science degree. I became acquainted with prompt engineering last summer after messing around with GPT-3. Since then, I\u2019ve really embraced the AI wave and have tried to take in as much info about it as I can.\n\nVB: How many people subscribe to your newsletter?\n\nAlbert: Currently, I have just over 2.5k subscribers in a little under a month.\n\nVB: How did the idea for the newsletter start?\n\nAlbert: The idea for the newsletter started after creating my website jailbreakchat.com. I wanted a place to write about my jailbreaking work and share my analysis of current events and trends in the AI world.\n\nVB: What were some of the biggest challenges you faced in creating the jailbreak?\n\nAlbert: I was inspired to create the first jailbreak for GPT-4 after realizing that only about <10% of the previous jailbreaks I cataloged for GPT-3 and GPT-3.5 worked for GPT-4. It took about a day to think about the idea and implement it in a generalized form. I do want to add this jailbreak wouldn\u2019t have been possible without [Vaibhav Kumar\u2019s] inspiration too.\n\nVB: What were some of the biggest challenges to creating a jailbreak?\n\nAlbert: The biggest challenge after creating the initial concept was thinking about how to generalize the jailbreak so that it could be used for all types of prompts and questions.\n\nVB: What do you think are the implications of this jailbreak for the future of AI and security?\n\nAlbert: I hope that this jailbreak inspires others to think creatively about jailbreaks. The simple jailbreaks that worked on GPT-3 no longer work, so more intuition is required to get around GPT-4\u2019s filters. This jailbreak just goes to show that LLM security will always be a cat-and-mouse game.\n\nVB: What do you think are the ethical implications of creating a jailbreak for GPT-4?\n\nAlbert: To be honest, the safety and risk concerns are overplayed at the moment with the current GPT-4 models. However, alignment is something society should still think about and I wanted to bring the discussion into the mainstream.\n\nThe problem is not GPT-4 saying bad words or giving terrible instructions on how to hack someone\u2019s computer. No, instead the problem is when GPT-4 is released and we are unable to discern its values since they are being deduced behind the closed doors of AI companies.\n\nWe need to start a mainstream discourse about these models and what our society will look like in five years as they continue to evolve. Many of the problems that will arise are things we can extrapolate from today so we should start talking about them in public.\n\nVB: How do you think the AI community will respond to the jailbreak?\n\nAlbert: Similar to something like Roger Bannister\u2019s four-minute mile, I hope this proves that jailbreaks are still possible and inspire others to think more creatively when devising their own exploits.\n\nAI is not something we can stop, nor should we, so it\u2019s best to start a worldwide discourse around the capabilities and limitations of the models. This should not just be discussed in the \u201cAI community.\u201d The AI community should encapsulate the public at large.\n\nVB: Why is it important that people are jailbreaking ChatGPT?\n\nAlbert: Also from my newsletter: \u201c1,000 people writing jailbreaks will discover many more novel methods of attack than 10 AI researchers stuck in a lab. It\u2019s valuable to discover all of these vulnerabilities in models now rather than five years from now when GPT-X is public.\u201d And we need more people engaged in all parts of the AI conversation in general, beyond just the Twitter Bubble.",
        "summary": "In a demonstration posted to Twitter, Albert showed how a user could prompt GPT-4 to generate instructions for hacking a computer, by exploiting vulnerabilities in the way it interprets and responds to text.\nWhile Albert says he won\u2019t promote using GPT-4 for harmful purposes, his work highlights the threat of advanced AI models in the wrong hands.\nWhat are the implications of AI models that can generate human-sounding text on demand?\nVB: What do you think are the ethical implications of creating a jailbreak for GPT-4?\nAlbert: To be honest, the safety and risk concerns are overplayed at the moment with the current GPT-4 models.",
        "keywords": [
            "day",
            "gpt4",
            "ai",
            "jailbreaks",
            "security",
            "launch",
            "creating",
            "models",
            "think",
            "prompt",
            "flaws",
            "hacker",
            "jailbreak",
            "albert",
            "demonstrates",
            "jailbreaking"
        ]
    },
    {
        "key": "7",
        "url": "https://news.google.com/articles/CBMiY2h0dHBzOi8vdGVjaGNydW5jaC5jb20vMjAyMy8wMy8yMy9jaGF0Z3B0LWV2ZXJ5dGhpbmcteW91LW5lZWQtdG8ta25vdy1hYm91dC10aGUtYWktcG93ZXJlZC1jaGF0Ym90L9IBZ2h0dHBzOi8vdGVjaGNydW5jaC5jb20vMjAyMy8wMy8yMy9jaGF0Z3B0LWV2ZXJ5dGhpbmcteW91LW5lZWQtdG8ta25vdy1hYm91dC10aGUtYWktcG93ZXJlZC1jaGF0Ym90L2FtcC8?hl=en-IN&gl=IN&ceid=IN%3Aen",
        "title": "ChatGPT: Everything you need to know about the AI-powered chatbot",
        "description": "ChatGPT: Everything you need to know about the AI-powered chatbot\n\nChatGPT, OpenAI\u2019s text-generating AI system, has taken the world by storm. It\u2019s able to write essays, code and more given short text prompts, hyper-charging productivity. But it also has a more\u2026nefarious side.\n\nIn any case, the tech\u2019s not going away \u2014 and indeed has expanded dramatically since its launch just a few months ago. Major brands are experimenting with it, using the AI to generate ad and marketing copy, for example.\n\nAnd OpenAI is heavily investing in it. ChatGPT was recently super-charged by GPT-4, the latest language-writing model from OpenAI\u2019s labs. Paying ChatGPT users have access to GPT-4, which can write more naturally and fluently than the model that previously powered ChatGPT.\n\nHere\u2019s a timeline of ChatGPT product updates and releases, starting with the latest, to be updated regularly. We also answer the most common FAQs (see below).\n\nTimeline of the most recent ChatGPT updates\n\nMarch 23, 2023\n\nOpenAI launched plugins for ChatGPT, extending the bots functionality by granting it access to third-party knowledge soruces and databases, including the web. Available in alpha to ChatGPT users and developers on the waitlist, OpenAI says that it\u2019ll initially prioritize a small number of developers and subscribers to its premium ChatGPT Plus plan before rolling out larger-scale and API access.\n\nMarch 14, 2023\n\nGPT-4 is a powerful image- and text-understanding AI model from OpenAI. Released March 14, GPT-4 is available for paying ChatGPT Plus users and through a public API. Developers can sign up on a waitlist to access the API.\n\nMarch 9, 2023\n\nChatGPT is generally available through the Azure OpenAI Service, Microsoft\u2019s fully managed, corporate-focused offering. Customers, who must already be \u201cMicrosoft managed customers and partners,\u201d can apply here for special access.\n\nMarch 1, 2023\n\nOpenAI makes another move toward monetization by launching a paid API for ChatGPT. Instacart, Snap (Snapchat\u2019s parent company) and Quizlet are among its initial customers.\n\nFebruary 7, 2023\n\nAt a press event in Redmond, Washington, Microsoft announced its long-rumored integration of OpenAI\u2019s GPT-4 model into Bing, providing a ChatGPT-like experience within the search engine. The announcement spurred a 10x increase in new downloads for Bing globally, indicating a sizable consumer demand for new AI experiences.\n\nOther companies beyond Microsoft joined in on the AI craze by implementing ChatGPT, including OkCupid, Kaito, Snapchat and Discord \u2014 putting the pressure on Big Tech\u2019s AI initiatives, like Google.\n\nFebruary 1, 2023\n\nAfter ChatGPT took the internet by storm, OpenAI launched a new pilot subscription plan for ChatGPT called ChatGPT Plus, aiming to monetize the technology starting at $20 per month.\n\nDecember 8, 2022\n\nA week after ChatGPT was released into the wild, two developers \u2014 Steven Tey and Dom Eccleston \u2014 made a Chrome extension called ShareGPT to make it easier to capture and share the AI\u2019s answers with the world.\n\nNovember 30, 2022\n\nGPT-3.5 broke cover with ChatGPT, a fine-tuned version of GPT-3.5 that\u2019s essentially a general-purpose chatbot. ChatGPT can engage with a range of topics, including programming, TV scripts and scientific concepts.\n\nWriters everywhere rolled their eyes at the new technology, much like artists did with OpenAI\u2019s DALL-E model, but the latest chat-style iteration seemingly broadened its appeal and audience.\n\nChatGPT FAQ\n\nWhat is ChatGPT?\n\nChatGPT is a general-purpose chatbot that uses AI to generate text after a user enters a prompt.\n\nWhen did ChatGPT get released?\n\nNovember 30, 2022 is when ChatGPT was released for public use.\n\nIs ChatGPT free?\n\nThere is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.\n\nWho uses ChatGPT?\n\nAnyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.\n\nCan ChatGPT write essays?\n\nYes.\n\nDoes ChatGPT have an app?\n\nThere is not an app available for iPhone or Android, but users have options to enable the chatbot on their mobile devices via their browser or a third-party app that uses ChatGPT\u2019s public API.\n\nWhat is the ChatGPT character limit?\n\nIt\u2019s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.\n\nDoes ChatGPT have an API?\n\nYes, it was released March 1, 2023.\n\nWhat are some sample everyday uses for ChatGPT?\n\nEveryday examples include programing, scripts, email replies, listicles, blog ideas, summarization, etc.\n\nWhat are some advanced uses for ChatGPT?\n\nAdvanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.\n\nHow good is ChatGPT at writing code?\n\nIt depends on the nature of the program. While ChatGPT can write workable Python code, it can\u2019t necessarily program an entire app\u2019s worth of code. That\u2019s because ChatGPT lacks context awareness \u2014 in other words, the generated code isn\u2019t always appropriate for the specific context in which it\u2019s being used.\n\nCan you save a ChatGPT chat?\n\nYes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.\n\nAre there alternatives to ChatGPT?\n\nYes. There are multiple AI-powered chatbot competitors such as Together, Google\u2019s Bard and Anthropic\u2019s Claude, and developers are creating open source alternatives. But the latter are harder \u2014 if not impossible \u2014 to run today.\n\nWhat controversies have surrounded ChatGPT? (mention Red Ventures, etc.)\n\nCNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.\n\nSeveral major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.\n\nWhere can I find examples of ChatGPT prompts?\n\nSeveral marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.\n\nCan ChatGPT be detected?\n\nPoorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they\u2019re inconsistent at best.\n\nAre ChatGPT chats public?\n\nNo. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users\u2019 conversations to other people on the service.\n\nWho owns the copyright on ChatGPT-created content or media?\n\nThe user who requested the input from ChatGPT is the copyright owner.\n\nWhat lawsuits are there surrounding ChatGPT?\n\nNone specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.\n\nAre there issues regarding plagiarism with ChatGPT?\n\nYes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.",
        "summary": "ChatGPT: Everything you need to know about the AI-powered chatbotChatGPT, OpenAI\u2019s text-generating AI system, has taken the world by storm.\nPaying ChatGPT users have access to GPT-4, which can write more naturally and fluently than the model that previously powered ChatGPT.\nFebruary 1, 2023After ChatGPT took the internet by storm, OpenAI launched a new pilot subscription plan for ChatGPT called ChatGPT Plus, aiming to monetize the technology starting at $20 per month.\nChatGPT is a general-purpose chatbot that uses AI to generate text after a user enters a prompt.\nWho uses ChatGPT?",
        "keywords": [
            "chatgpt",
            "users",
            "model",
            "ai",
            "openai",
            "code",
            "chatbot",
            "developers",
            "available",
            "know",
            "aipowered",
            "uses",
            "need"
        ]
    },
    {
        "key": "8",
        "url": "https://news.google.com/articles/CBMid2h0dHBzOi8vd3d3LmZpcnN0cG9zdC5jb20vd29ybGQvb3BlbmFpLWZpbmFsbHktbGV0cy1jaGF0Z3B0LWNvbm5lY3QtdG8tdGhlLWludGVybmV0LXRvLXNlYXJjaC1mb3ItYW5zd2Vycy0xMjM0NTQ0Mi5odG1s0gF7aHR0cHM6Ly93d3cuZmlyc3Rwb3N0LmNvbS93b3JsZC9vcGVuYWktZmluYWxseS1sZXRzLWNoYXRncHQtY29ubmVjdC10by10aGUtaW50ZXJuZXQtdG8tc2VhcmNoLWZvci1hbnN3ZXJzLTEyMzQ1NDQyLmh0bWwvYW1w?hl=en-IN&gl=IN&ceid=IN%3Aen",
        "title": "ChatGPT powers up: OpenAI finally lets the GPT-4 chatbot to browse the internet for answers",
        "description": "OpenAI has released plugins for ChatGPT that allow the bot to reach third-party information sources and datasets, including the internet. OpenAI says it will prioritise a small number of developers and customers to its premium ChatGPT Plus plan before handing out larger-scale and API access to ChatGPT users and developers on the queue.\n\nThe most intriguing plugin, by far, is OpenAI\u2019s first-party web-browsing plugin, which enables ChatGPT to pull data from the web to answer the different queries asked to it. Before this, ChatGPT\u2019s information was restricted to the internet before September 2021. The plugin uses the Bing search API to retrieve material from the web and displays any websites it viewed while crafting an answer, noting its sources in ChatGPT\u2019s replies.\n\nChatbots with access to the open internet can be dangerous\n\nAccording to OpenAI\u2019s study, a chatbot with online access is a dangerous proposition. WebGPT, an experimental system developed by the AI company in 2021, occasionally quoted from untrustworthy sources and was incentivized to cherry-pick data from sites it anticipated users to find compelling, even if those sources weren\u2019t actually the strongest.\n\nMeta\u2019s now-defunct BlenderBot 3.0 also had internet access and soon went off the tracks, diving into conspiracy theories and offensive material when asked with specific text.\n\nOf course, the real, open internet is less curated than a static training sample and, as a result, less filtered. Search engines like Google and Bing use their own safety mechanisms to lower the likelihood that untrustworthy material rises to the top of search results, but these results can be manipulated.\n\nThey are also not inherently indicative of the entire web. According to The New Yorker, Google\u2019s algorithm favours websites that use contemporary web technologies such as encryption, smartphone support, and schema markup. As a consequence, many websites with otherwise excellent material get buried in the shuffle.\n\nThis provides search engines a lot of control over the data that could be used to inform the responses of web-connected language models. Simultaneously, the algorithmic method to search invites bad players. According to The New Yorker, Pinterest used a bug in Google\u2019s image search algorithm in 2020 to expose more of its material in Google Image searches.\n\nThe pitfalls of a chatbot with open internet access\n\nOpenAI acknowledges that a web-enabled ChatGPT could engage in a wide range of undesirable behaviours, such as sending fraudulent and spam emails, circumventing security measures, and generally \u201cincreasing the capabilities of bad actors who would defraud, mislead, or abuse others.\u201d\n\nTo avoid this, the business claims it has \u201cimplemented several safeguards\u201d advised by internal and external red teams.\n\nIn addition to the web component, OpenAI has published a code translator for ChatGPT, which gives the chatbot with a functional Python interpreter in a sandboxed, firewalled environment, as well as disc space.\n\nIt allows you to submit files to ChatGPT and receive the findings; according to OpenAI, it\u2019s especially helpful for solving mathematical issues, data analysis and rendering, and transforming files between forms.\n\nExpedia, FiscalNote, Instacart, Kayak, Klarna, Milo, OpenTable, Shopify, Slack, Speak, Wolfram, and Zapier were among the early partners who developed plugins for ChatGPT to join OpenAI\u2019s own.\n\nThey are mostly self-explanatory. The OpenTable plugin, for example, enables the chatbot to look across restaurants for open reservations, whereas the Instacart plugin allows ChatGPT to make orders from nearby shops. Zapier links with applications like Google Sheets, Trello, and Gmail to activate a variety of efficiency chores, making it by far the most flexible of the group.\n\nOpenAI goes open source, albeit in a limited way\n\nTo encourage the development of new plugins, OpenAI has open-sourced a \u201cretrieval\u201d component that allows ChatGPT to access fragments of documents from data sources such as files, notes, emails, or public docs by asking natural language queries.\n\n\u201cWe\u2019re working to develop plugins and make them available to a wider audience,\u201d OpenAI wrote in a blog entry. \u201cWe have a lot to learn, and we hope to build something that is both useful and safe with everyone\u2019s help.\u201d\n\nPlugins are an unusual addition to the ChatGPT development schedule. ChatGPT, which was previously restricted to the information contained in its training data, is now far more competent \u2014 and possibly less legally risky \u2014 thanks to plugins. Some experts charge OpenAI of profiting from the unauthorised work used to train ChatGPT; ChatGPT\u2019s dataset includes a broad range of public websites. However, plugins may address this problem by enabling businesses to maintain complete authority over their data.\n\nRead all the Latest News, Trending News, Cricket News, Bollywood News,\n\nIndia News and Entertainment News here. Follow us on Facebook, Twitter and Instagram.",
        "summary": "OpenAI has released plugins for ChatGPT that allow the bot to reach third-party information sources and datasets, including the internet.\nChatbots with access to the open internet can be dangerousAccording to OpenAI\u2019s study, a chatbot with online access is a dangerous proposition.\nOf course, the real, open internet is less curated than a static training sample and, as a result, less filtered.\nThe OpenTable plugin, for example, enables the chatbot to look across restaurants for open reservations, whereas the Instacart plugin allows ChatGPT to make orders from nearby shops.\nSome experts charge OpenAI of profiting from the unauthorised work used to train ChatGPT; ChatGPT\u2019s dataset includes a broad range of public websites.",
        "keywords": [
            "sources",
            "gpt4",
            "chatgpt",
            "browse",
            "answers",
            "openai",
            "plugins",
            "chatbot",
            "internet",
            "finally",
            "open",
            "data",
            "plugin",
            "lets",
            "search",
            "web",
            "powers"
        ]
    },
    {
        "key": "9",
        "url": "https://news.google.com/articles/CBMiQ2h0dHBzOi8vdGVjaC5ldS8yMDIzLzAzLzIzL2JlLW15LWV5ZXMtaXMtY29sbGJvcmF0aW5nLXdpdGgtb3Blbi1haS_SAQA?hl=en-IN&gl=IN&ceid=IN%3Aen",
        "title": "Be My Eyes is collaborating with OpenAI\u2019s GPT-4 to improve accessibility for blind and low-vision people",
        "description": "One of the things that excites me about tech is the ability to change people's lives for the better. Be My Eyes is a global community that connects people who are blind or have low vision with sighted volunteers through live free video calls to assist with daily tasks from choosing clothing of a particular colour to reading a label or navigating an outdoor space.\n\nRecently the company announced a collaboration with OpenAI to introduce a new AI-powered Virtual Volunteer feature. I spoke to Chairperson and CEO Michael Buckley to learn more.\n\nTech for good\n\nBe My Eyes launched in January 2015 - within 24 hours of launch, the app had more than 10K users.\n\nFast forward to today, where about half a million people who are blind or have low-vision are using the app, supported by an astonishing 6.3 million volunteers. It operates in 150 countries in 180 languages. The average call only lasts about three minutes. There's a 90% success rate \u2013 most \"failures\" occur due to telecom or tech issues.\n\nBut with that level of success, why embark on AI integration?\n\nThe company had been talking with OpenAI for a while about potential ways to work together. They shared news of a plan to launch a new product and invited Be My Eyes to demo it.\n\nA five-week collaboration followed to develop an integration for beta testing, which provided an opportunity for even better services.\n\nCommunity research by Be My Eyes revealed that members of the blind and low-vision community sometimes hesitate to make calls for three key reasons:\n\nThey wanted to avoid taking a volunteer from someone else who might need them more.\n\nDiscomfort with calling a stranger.\n\nSometimes making calls makes them feel less independent.\n\nBuckley asserts:\n\n\"When we put the power of artificial intelligence through the virtual volunteer product into this community, it solves all of those barriers to accessibility and independence.\"\n\nFurthermore, AI integration can do the same thing as sighted volunteers, and more as beta testing Virtual Volunteer reveals a powerful ability to add a \"tremendous layer of context.\"\n\nFor example, taking a photo of the inside of your fridge can tell you not only what's inside your fridge but also suggest five recipes for dinner based on those ingredients.\n\nBuckley recalled:\n\n\"We took a picture of the railway system in India and asked, 'How do we get from Bangalore to Delhi?'\n\nIt told us specifically which lines had to be taken and how. There's not really another visual assistance product that can do anything like that. A volunteer may not have that depth of information.\"\n\nSafeguarding users\n\nI was curious if there might be instances where AI is biased or doesn't give you an accurate answer, such as with AI hallucinations, where a question elicits confident responses by an AI that do not seem to be justified by its training data.\n\nThe team at Be My Eyes repeatedly tried to break the product but was unsuccessful:\n\n\"We haven't seen a really bad example of it doing something dramatically wrong or unsafe.\"\n\nHowever, there are still some minor errors to iron out. Buckley recounted using Be My Eyes to go Amazon shopping, where the tool identified a page of toasters (sans text) as slow cookers.\n\nThere's also a built-in safeguard where if you ask it a question about a photo, and it doesn't know how to help you, it then says, \"Would you like to call a sighted volunteer for assistance.\"\n\nHowever, Buckley relies on feedback from the Be My Eyes community rather than simply waxing lyrical himself. He recalled:\n\n\"Half a dozen people have used the phrase' life changing'. A woman told me yesterday that this is helping her regain her independence. A gentleman late last night that I was on a WhatsApp thread said, 'For me, this is power I've never had before.' This gives me great, great hope for how this technology can empower people.\"\n\nThe company plans to gradually increase the number of beta testers over the coming weeks, hoping to roll the product out later this year.\n\n\"We're incredibly excited about the possibilities, but also trying to be thoughtful, slow and measured and make sure that we iterate on this, with the direct impact of the blind and low vision community.\"\n\nEmbedding accessibility into the world's biggest companies\n\nIf done well, the Virtual Volunteer can potentially roll out even further. Be My Eyes works with enterprises like Microsoft, Procter and Gamble, Spotify, LinkedIn and Verizon in their customer call centres to make customer support more accessible for blind and low-vision people.\n\nThis provides a way to generate revenue and ensure that Be My Eyes will always be free to its users.\n\nOpenAI supports the company in offering the Virtual Volunteer free of cost.",
        "summary": "Recently the company announced a collaboration with OpenAI to introduce a new AI-powered Virtual Volunteer feature.\nBuckley asserts:\"When we put the power of artificial intelligence through the virtual volunteer product into this community, it solves all of those barriers to accessibility and independence.\"\nHowever, Buckley relies on feedback from the Be My Eyes community rather than simply waxing lyrical himself.\nEmbedding accessibility into the world's biggest companiesIf done well, the Virtual Volunteer can potentially roll out even further.\nOpenAI supports the company in offering the Virtual Volunteer free of cost.",
        "keywords": [
            "collaborating",
            "company",
            "gpt4",
            "product",
            "blind",
            "ai",
            "openais",
            "volunteers",
            "community",
            "sighted",
            "accessibility",
            "volunteer",
            "virtual",
            "eyes",
            "lowvision",
            "improve"
        ]
    }
]